---
title: "Introduction"
execute:
  freeze: true
editor:
  markdown:
    wrap: 72
output:
  html_document:
    df_print: tibble
---

```{r setup, include=FALSE, paged.print=TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  paged.print=FALSE # this seemingly doesn't do anything
)
library(dplyr, warn.conflicts = FALSE)
library(guildai)


Sys.setenv(PATH = paste0(R.home("bin"), ":", Sys.getenv("PATH")))
for(v in c("VIRTUAL_ENV", "PYTHONHOME", "PYTHONPATH")) Sys.unsetenv(v)
Sys.setenv("RETICULATE_PYTHON" = "~/.virtualenvs/r-tensorflow/bin/python")
Sys.setenv("TF_CPP_MIN_LOG_LEVEL" = "2")

if(!interactive())
  unlink(".guild", recursive = TRUE)

# help knitr capture stdout 
guild_run <- function(..., flags = NULL, echo = TRUE) {
  stdout <- stderr <- echo
  flags$.fast <- interactive()
  out <- guildai::guild_run(..., flags = flags, stdout = stdout, stderr = stderr)
  try(writeLines(out))
  invisible(out)
}
Sys.setenv("GUILD_HOME" = normalizePath(file.path(getwd(), ".guild"),
                                        mustWork = FALSE))

```

<!-- a nice screenshot image here-->

*guildai* provides a suite of tools for tracking, visualizing, and
managing training runs and experiments. The {guildai} R package is a
successor to the {tfruns} package.

-   Track the hyperparameters, metrics, output, and source code of every
    training run.

-   Compare hyperparmaeters and metrics across runs to find the best
    performing model.

-   Automatically generate reports to visualize individual training runs
    or comparisons between runs.

-   No changes to source code required.

## Installation

The R package provides an interface to [guildai
core](https://guild.ai/). The R package will auomatically guildai core
on first use, or you can call `install_guild()` directly to customize
the installation. You can install the **guildai** package from CRAN as
follows:

```{r, eval = FALSE}
install.packages("guildai")
guildai::install_guild()
```

{guildai} can be used with any machine learning framework, or even no
framework at all. For this introductory example, we'll start with a
Keras model applied to the fashion mnist dataset.

If you've not used Keras from R before and you want to follow along on
your machine, you can install it like this:

```{r, eval = FALSE}
install.packages("keras")
library(keras)
install_keras()
```

## Hello World

### Launch a run

To start, we'll setup a sample project folder with one script.

```{r copy-fashion-mnist}
file.copy(system.file("examples/fashion-mnist.R", package = "guildai"),
          ".", overwrite = TRUE)
```

Here is what the training script looks like:

```{r}
#| file: !expr "'fashion-mnist.R'"
#| eval: false
```

To train a model with **guildai**, use the `guild_run()` function in
place of the `source()` function to execute your R script. For example:

```{r}
guild_run("fashion-mnist.R")
```

This will launch a new process in an isolated run directory using the
provided script. By default, the output stream from the run will be
shown at the R console (the same output stream you would see with
`source("fashion-mnist.R", echo = TRUE)` or `Rscript fashion-mnist.R`).

### View Runs

You can view your runs (including while they are running) with the
"Guild View" application, by calling `guild_view()`. The Guild View

```{r, eval = FALSE}
guild_view()
```

TODO: SCREENSHOT

You can retrieve a data frame with run information using `ls_runs()`:

```{r}
run <- ls_runs()
tibble::glimpse(run)
```

`ls_runs()` returns a data frame with information about runs. In our
sample project, we've launched one run, so `ls_runs()` returns a 1-row
data frame.

### Run Directories

`guild_view()` and `ls_runs()` provide two convenient ways to gather and
present the information from runs. Importantly however, the run
directory is easily accessible, where everything about the run is
available as plain text files. The run directory also contain any
artifacts generated by the run process, like model check points.

```{r}
fs::dir_tree(run$dir, all=TRUE)
```

A run can also be used to generate a summary report, a paramaterized
quarto document:

```{r eval=FALSE}
view_run_report(run$id)
```

### Comparing Runs

Let's make a couple of changes to our training script to see if we can
improve model performance. We'll change the number of units in our first
dense layer to 128, change the `learning_rate` from 0.001 to 0.003 and
run 30 rather than 20 `epochs`. After making these changes to the source
code we re-run the script using `guild_run()` as before:

```{r, echo = FALSE}
guildai:::modify_r_file_flags("fashion-mnist.R", 
  list(units = 128, learning_rate = 0.003, epochs = 30),
  overwrite = TRUE)
```

```{r results=FALSE}
guild_run("fashion-mnist.R")
```

This will also show us a report summarizing the results of the run, but
what we are really interested in is a comparison between this run and
the previous one.

The individual metrics `test_loss` and `test_accuracy` are visible in
the comparison table in the Guild View application, as well as in the We
can view a comparison via the `view_runs_diff()` function:

```{r, eval = FALSE}
view_runs_diff()
```

The comparison report shows the model attributes and metrics
side-by-side, as well as differences in the source code and output of
the training script.

Note that `view_runs_diff()` will by default compare the last two runs,
however you can pass any two run ids you like to be compared.

```{r restore-fashion-mnist, echo = FALSE}
file.copy(system.file("examples/fashion-mnist.R", package = "guildai"),
          ".", overwrite = TRUE)
```

## Flags

Flags are a form of run inputs, or paramaterization. The action we just
described, of modifying `learning_rate`, `epochs` and `units` values in
the script before launching the second run, can be performed by
`guild_run()` using the *flags* interface.

By default, guild identifies all top-level assignments of scalar
literals in an R script as *run flags* that can be modified per-run. You
can quickly see what flags are available in an R script by passing
`--help-op` (more on this later).

```{r}
guild_run("fashion-mnist.R", "--help-op")
```

You can launch a run with different flag values like this:

```{r, eval=FALSE}
    guild_run("fashion-mnist.R", 
              flags = list(learning_rate = 0.001, 
                           units = 256))
```

Now, when we inspect the run sources with `view_runs_diff()`, we see
that the source file from the last run has updated flag values, as if we
had modified them manually.

The flags interface is useful for hyperparamater optimization. At it's
simplest, you can use just iterate over the set of flag values you want
and pass them to `guild_run()`:

```{r, eval = FALSE}
for (learning_rate in c(0.001, 0.0003))
  guild_run("fashion-mnist.R", c(learning_rate = learning_rate))
```

You can also pass multiple values for each flag, and guild will
automatically expand the combinations to a grid search. For example,
this will launch 4 training runs, with each combination of flag values:

```{r, eval = FALSE}
guild_run("fashion-mnist.R", 
          flags = list(learning_rate = c(0.001, 0.003),
                       units = c(128, 256)))
```

Another way to launch a batch of runs is to pass a dataframe of flags
values, with each row corresponding to a run.

```{r, eval = TRUE}
flags_df <- expand.grid(learning_rate = c(0.001, 0.003),
                        units = c(128, 256))
flags_df
```

```{r, eval = FALSE}
guild_run("fashion-mnist.R", flags = flags_df)
```

### Flag annotations

You can optionally supply additional metadata about individual flags by
placing hashpipe yaml annotations above the flag expression. For
example, we can update our "fashion-mnist.R" script with the following
lines:

    #| description: size of first layer.
    #| min: 16
    #| max: 256
    units <- 32

    #| description: Activation function to use.
    #| choices: [relu, sigmoid, tanh]
    activation <- "relu"

Now, the `description`s and constraints will appear in `--help-op` and
related locations.

### Flag destinations

As a project grows, it's helpful to be able to move flag definitions out
of the main R script. To do so, you can include a `flags-dest` in the
frontmatter of the R script, specifying the file where guild should
update the flag values. Then you can read in the flags using `source()`
or similar.

    #| flags-dest: ./flags.R

    FLAGS <- envir::include("flags.R", new.env())

YAML files are also supported as a flags destination:

    #| flags-dest: ./flags.yml

    FLAGS <- yaml::read_yaml("flags.yml")

### Retreiving Run Flags

The flags and flag values associated with each runs are returned by
`ls_runs()` as a nested dataframe under `flags`.

```{r paged.print=FALSE}
runs <- ls_runs()
runs %>%
  select(id, flags)
```

## Scalars

The counterpart to run `flags` are run `scalars`. Whereas `flags` are a
a special type of run input that guild can help manage, scalars are
special type of run output that guild can help manage.

```{r paged.print=FALSE}
runs %>%
  select(id, scalars)

glimpse(runs$scalars[[1]])
```

```{r include = FALSE, eval=FALSE, include=FALSE}
guild_view()
view_run_report()
```

Here we see that guild has automatically identified `test_accuracy` and
`test_loss` as run scalar outputs. By default, any lines printed to
standard output during the run with the pattern `"key: <numeric-value>"`
are recorded by guild as `scalars`. If you are printing values for the
same scalar `key` multiple times during a run (e.g, `loss` during a
training loop), then be sure to also print a `step` scalar in between,
to enable guild to track history (and enable visualization of the run
metrics with tensorboard).

If your run process produces tfevent records directly (e.g.,
`keras::callback_tensorboard("./logs")`), then those are also
automatically identified by guild a run scalars, and included in
`ls_runs()` (and `guild_view()`, and tensorboard and other run views).

`ls_runs()` returns a summary of run scalars, but the full set of
scalars observed in runs can also be accessed from R directly:

```{r, paged.print=FALSE}
ls_scalars()
```

## Managing runs

Guild comes with a comprehensive set of functions for managing runs.

-   annotate runs: `runs_comment()`, `runs_mark()` and `runs_tag()`.
-   move, archive, or copy runs: `runs_export()` and `runs_import()`
-   delete runs: `runs_delete()` `runs_purge()` `runs_restore()`

The `runs_*` family of functions all take `runs` as a first argument,
and can be conveniently composed with `%>%` and `ls_runs()` or
`ls_scalars()`. For example:

```{r paged.print=FALSE}
library(dplyr)

top3_runs <- ls_scalars() %>% 
  filter(tag == "test_accuracy") %>% 
  slice_max(value, n = 3)

top3_runs

top3_runs %>% 
  runs_tag("top3") %>% 
  runs_export("./top3-runs")
```

`runs` can be supplied like a dataframe returned by `ls_runs()` or
`ls_scalars()` like in the example above. `runs` can also be a character
vector where there is a flexible syntax supported for specifying runs
selections. See `?resolve_run_ids()` for details.

## Using guild from the terminal

`guild` can also be used directly from the terminal. Call the R function
`export_guild_cli()` to place the `guild` executable on your PATH:

```{r, eval = FALSE}
export_guild_cli(dest = "~/bin")
```

Then you can launch runs and perform other guild operations from the
terminal:

``` bash
guild run fashion-mnist.R
guild run fashion-mnist.R batch_size='[32,64]'
```

As you move between the terminal and the R console, almost all of the
same syntax supported from the terminal can be used from R by passing
strings:

```{r, eval = FALSE}
guild_run("fashion-mnist.R", 'batch_size=[32,64]')
```

```{r}
knitr::knit_exit()
```

## Using Flags and Scalars Together

To tie things together, we'll use guild to explore what impact `units`
has on `test_accuracy`.

```{r}
units <- (2 ^ (4:11)) %>% c(diff(., 2)) %>% sort()
units 
guild_run("fashion-mnist.R", 
          flags = list(units = units),
          echo = FALSE)
```

We can see compare run flags and run scalars from R:

```{r paged.print=FALSE}
runs <- ls_runs(paste0("1:", length(units))) # last 8 runs

df <- runs %>%
  select(flags, scalars) %>%
  rowwise() %>%
  mutate(across(scalars, function(run_scalars_df) {
    run_scalars_df %>%
      select(tag, last_val) %>%
      tidyr::pivot_wider(names_from = tag,
                         values_from = last_val)
  })) %>%
  tidyr::unnest(c(flags, scalars)) %>%
  arrange(units) 

df
```

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(df, aes(x = units, y = test_accuracy)) +
  geom_point() + geom_smooth()
```

### Addin

The **guildai** package installs an RStudio IDE addin which provides
quick access to frequently used functions from the Addins menu:

Note that you can use **Tools** -\> **Modify Keyboard Shortcuts** within
RStudio to assign a keyboard shortcut to one or more of the addin
commands.

### Background Training

Since training runs can become quite lengthy, it's often useful to run
them in the background in order to keep the R console free for other
work. You can launch a guild run without blocking the R console by
specifying `guild_run(wait = FALSE)` in the call. You can then view
real-time outputs from your run(s) using `guild_view()`.

Alternatively, you can launch training runs in the terminal pane:

    Rscript -e 'guildai::guild_run("train.R")'

If you are not running within RStudio then you can of course use a
system terminal window for background training.

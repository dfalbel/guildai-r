[{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Introduction","text":"R package provides interface guildai core. R package install guildai core first use, can call install_guild() customize installation. can install guildai package CRAN follows: {guildai} can used machine learning framework, even framework . introductory example, ’ll start Keras model applied fashion mnist dataset. ’ve used Keras R want follow along machine, can install like :","code":"install.packages(\"guildai\") guildai::install_guild() install.packages(\"keras\") library(keras) install_keras()"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"hello-world","dir":"Articles","previous_headings":"","what":"Hello World","title":"Introduction","text":"start, ’ll setup sample project folder one script. training script looks like: train model guildai, just use guild_run() function place source() function execute R script. example: default, output stream run shown R console. launching run, can launch application view runs guild_view(). Guild View application, can also visualize run results using tensorboard. can also retrieve data frame information run ls_runs(): ls_runs() returns data frame information runs. sample project, ’ve launched one run, ls_runs() returns 1-row data frame. guild_view() ls_runs() provide two convenient ways gather present information runs. Importantly however, information run stored plain files. run can also used generate summary report, paramaterized quarto document:","code":"file.copy(system.file(\"examples/fashion-mnist.R\", package = \"guildai\"),           \".\", overwrite = TRUE) #> [1] TRUE library(keras)  # Prepare data ---- fashion_mnist <- dataset_fashion_mnist()  c(train_images, train_labels) %<-% fashion_mnist$train c(test_images, test_labels) %<-% fashion_mnist$test  train_images <- train_images / 255  test_images <- test_images / 255  # Define model ----  units <- 64  model <- keras_model_sequential(input_shape = c(28, 28)) model %>%   layer_flatten() %>%   layer_dense(units = units, activation = 'relu') %>%   layer_dense(units = 10, activation = 'softmax')   learning_rate <- 0.001  model %>% compile(   optimizer = optimizer_adam(learning_rate),   loss = 'sparse_categorical_crossentropy',   metrics = c('accuracy') )  model  # Fit model ----  batch_size <- 32 epochs <- 20  .fast <- TRUE if (.fast) {   n <- 1:20   train_images %<>% { .[n, ,] }   test_images %<>% { .[n, ,] }   test_labels %<>% { .[n] }   train_labels %<>% { .[n] }   epochs <- 2 }  history <- model %>%   fit(train_images, train_labels,       validation_split = 0.2,       batch_size = batch_size,       epochs = epochs,       verbose = 2)  plot(history)  # Evaluate model ----  score <- model %>%   evaluate(test_images, test_labels,            verbose = 0) %>%   as.list()  cat('test_loss:', score$loss, \"\\n\") cat('test_accuracy:', score$accuracy, \"\\n\")  # save_model_tf(model, \"model.keras\") # saveRDS(history, \"history.rds\") guild_run(\"fashion-mnist.R\") #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:29:42.766877: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 64 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 64)                      50240        #>  dense (Dense)                      (None, 10)                      650          #> ================================================================================ #> Total params: 50,890 #> Trainable params: 50,890 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 20 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/20 #> 1500/1500 - 4s - loss: 0.5456 - accuracy: 0.8106 - val_loss: 0.4383 - val_accuracy: 0.8480 - 4s/epoch - 2ms/step #> Epoch 2/20 #> 1500/1500 - 2s - loss: 0.4089 - accuracy: 0.8545 - val_loss: 0.4082 - val_accuracy: 0.8521 - 2s/epoch - 2ms/step #> Epoch 3/20 #> 1500/1500 - 3s - loss: 0.3707 - accuracy: 0.8678 - val_loss: 0.3700 - val_accuracy: 0.8667 - 3s/epoch - 2ms/step #> Epoch 4/20 #> 1500/1500 - 3s - loss: 0.3474 - accuracy: 0.8732 - val_loss: 0.3619 - val_accuracy: 0.8707 - 3s/epoch - 2ms/step #> Epoch 5/20 #> 1500/1500 - 3s - loss: 0.3267 - accuracy: 0.8802 - val_loss: 0.3920 - val_accuracy: 0.8585 - 3s/epoch - 2ms/step #> Epoch 6/20 #> 1500/1500 - 3s - loss: 0.3132 - accuracy: 0.8865 - val_loss: 0.3505 - val_accuracy: 0.8763 - 3s/epoch - 2ms/step #> Epoch 7/20 #> 1500/1500 - 3s - loss: 0.2995 - accuracy: 0.8901 - val_loss: 0.3623 - val_accuracy: 0.8711 - 3s/epoch - 2ms/step #> Epoch 8/20 #> 1500/1500 - 3s - loss: 0.2892 - accuracy: 0.8950 - val_loss: 0.3411 - val_accuracy: 0.8799 - 3s/epoch - 2ms/step #> Epoch 9/20 #> 1500/1500 - 2s - loss: 0.2774 - accuracy: 0.8970 - val_loss: 0.3286 - val_accuracy: 0.8837 - 2s/epoch - 2ms/step #> Epoch 10/20 #> 1500/1500 - 2s - loss: 0.2701 - accuracy: 0.9006 - val_loss: 0.3225 - val_accuracy: 0.8866 - 2s/epoch - 2ms/step #> Epoch 11/20 #> 1500/1500 - 3s - loss: 0.2606 - accuracy: 0.9033 - val_loss: 0.3427 - val_accuracy: 0.8799 - 3s/epoch - 2ms/step #> Epoch 12/20 #> 1500/1500 - 2s - loss: 0.2532 - accuracy: 0.9070 - val_loss: 0.3423 - val_accuracy: 0.8834 - 2s/epoch - 2ms/step #> Epoch 13/20 #> 1500/1500 - 2s - loss: 0.2468 - accuracy: 0.9086 - val_loss: 0.3337 - val_accuracy: 0.8859 - 2s/epoch - 2ms/step #> Epoch 14/20 #> 1500/1500 - 2s - loss: 0.2414 - accuracy: 0.9100 - val_loss: 0.3748 - val_accuracy: 0.8712 - 2s/epoch - 2ms/step #> Epoch 15/20 #> 1500/1500 - 2s - loss: 0.2353 - accuracy: 0.9138 - val_loss: 0.3375 - val_accuracy: 0.8839 - 2s/epoch - 2ms/step #> Epoch 16/20 #> 1500/1500 - 2s - loss: 0.2309 - accuracy: 0.9147 - val_loss: 0.3452 - val_accuracy: 0.8855 - 2s/epoch - 2ms/step #> Epoch 17/20 #> 1500/1500 - 2s - loss: 0.2230 - accuracy: 0.9170 - val_loss: 0.3336 - val_accuracy: 0.8881 - 2s/epoch - 2ms/step #> Epoch 18/20 #> 1500/1500 - 2s - loss: 0.2184 - accuracy: 0.9194 - val_loss: 0.3408 - val_accuracy: 0.8850 - 2s/epoch - 2ms/step #> Epoch 19/20 #> 1500/1500 - 2s - loss: 0.2143 - accuracy: 0.9202 - val_loss: 0.3514 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step #> Epoch 20/20 #> 1500/1500 - 2s - loss: 0.2113 - accuracy: 0.9211 - val_loss: 0.3433 - val_accuracy: 0.8845 - 2s/epoch - 2ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.3687011  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.882  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > guild_view() run <- ls_runs() str(run) #> tibble [1 × 17] (S3: tbl_df/tbl/data.frame) #>  $ shortId   : chr \"f4375fbc\" #>  $ label     : chr \".fast=no batch_size=32.0 epochs=20.0 learning_rate=0.001 units=64.0\" #>  $ flags     : tibble [1 × 5] (S3: tbl_df/tbl/data.frame) #>   ..$ .fast        : logi FALSE #>   ..$ batch_size   : num 32 #>   ..$ epochs       : num 20 #>   ..$ learning_rate: num 0.001 #>   ..$ units        : num 64 #>  $ scalars   :List of 1 #>   ..$ : tibble [2 × 14] (S3: tbl_df/tbl/data.frame) #>   .. ..$ run       : chr [1:2] \"f4375fbcfa6b4158b9f8017d87affad7\" \"f4375fbcfa6b4158b9f8017d87affad7\" #>   .. ..$ prefix    : chr [1:2] \".guild\" \".guild\" #>   .. ..$ tag       : chr [1:2] \"test_accuracy\" \"test_loss\" #>   .. ..$ first_val : num [1:2] 0.882 0.369 #>   .. ..$ first_step: int [1:2] 0 0 #>   .. ..$ last_val  : num [1:2] 0.882 0.369 #>   .. ..$ last_step : int [1:2] 0 0 #>   .. ..$ min_val   : num [1:2] 0.882 0.369 #>   .. ..$ min_step  : int [1:2] 0 0 #>   .. ..$ max_val   : num [1:2] 0.882 0.369 #>   .. ..$ max_step  : int [1:2] 0 0 #>   .. ..$ avg_val   : num [1:2] 0.882 0.369 #>   .. ..$ total     : num [1:2] 0.882 0.369 #>   .. ..$ count     : int [1:2] 1 1 #>  $ dir       : chr \"/home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/f4375fbcfa6b4158b9f8017d87affad7\" #>  $ operation : chr \"fashion-mnist.R\" #>  $ started   : POSIXct[1:1], format: \"2022-10-21 13:29:41\" #>  $ stopped   : POSIXct[1:1], format: \"2022-10-21 13:30:39\" #>  $ time      : chr \"0:00:58\" #>  $ tags      : chr \"\" #>  $ comments  :List of 1 #>   ..$ : chr(0)  #>  $ status    : chr \"completed\" #>  $ exitStatus: int 0 #>  $ otherAttrs:'data.frame':  1 obs. of  0 variables #>  $ deps      :List of 1 #>   ..$ : list() #>  $ projectDir: chr \"/home/tomasz/guild/guildai-r/vignettes/articles\" #>  $ id        : chr \"f4375fbcfa6b4158b9f8017d87affad7\" fs::dir_tree(run$dir, all=TRUE) #> /home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/f4375fbcfa6b4158b9f8017d87affad7 #> ├── .guild #> │   ├── attrs #> │   │   ├── cmd #> │   │   ├── deps #> │   │   ├── env #> │   │   ├── exit_status #> │   │   ├── flags #> │   │   ├── host #> │   │   ├── id #> │   │   ├── initialized #> │   │   ├── label #> │   │   ├── op #> │   │   ├── platform #> │   │   ├── random_seed #> │   │   ├── run_params #> │   │   ├── sourcecode_digest #> │   │   ├── started #> │   │   ├── stopped #> │   │   ├── user #> │   │   ├── user_flags #> │   │   └── vcs_commit #> │   ├── events.out.tfevents.1666373439.horse.40983.0 #> │   ├── manifest #> │   ├── opref #> │   ├── output #> │   ├── output.index #> │   └── sourcecode #> │       └── fashion-mnist.R #> └── plots #>     └── Rplot001.png view_run_report(run$id)"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"comparing-runs","dir":"Articles","previous_headings":"Hello World","what":"Comparing Runs","title":"Introduction","text":"Let’s make couple changes training script see can improve model performance. ’ll change number units first dense layer 128, change learning_rate 0.001 0.003 run 30 rather 20 epochs. making changes source code re-run script using guild_run() : also show us report summarizing results run, really interested comparison run previous one. individual metrics test_loss test_accuracy visible comparison table Guild View application, well can view comparison via view_runs_diff() function: comparison report shows model attributes metrics side--side, well differences source code output training script. Note view_runs_diff() default compare last two runs, however can pass two run ids like compared.","code":"#> Replaced expression 'units <- 64' on line 14 with 'units <- 128' #> Replaced expression 'learning_rate <- 0.001' on line 23 with 'learning_rate <- 0.003' #> Replaced expression 'epochs <- 20' on line 36 with 'epochs <- 30' guild_run(\"fashion-mnist.R\") #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:30:42.601807: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/30 #> 1500/1500 - 3s - loss: 0.4960 - accuracy: 0.8217 - val_loss: 0.5522 - val_accuracy: 0.8076 - 3s/epoch - 2ms/step #> Epoch 2/30 #> 1500/1500 - 2s - loss: 0.3872 - accuracy: 0.8581 - val_loss: 0.4036 - val_accuracy: 0.8539 - 2s/epoch - 2ms/step #> Epoch 3/30 #> 1500/1500 - 2s - loss: 0.3562 - accuracy: 0.8684 - val_loss: 0.3957 - val_accuracy: 0.8576 - 2s/epoch - 2ms/step #> Epoch 4/30 #> 1500/1500 - 2s - loss: 0.3318 - accuracy: 0.8772 - val_loss: 0.3620 - val_accuracy: 0.8702 - 2s/epoch - 2ms/step #> Epoch 5/30 #> 1500/1500 - 2s - loss: 0.3131 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8674 - 2s/epoch - 2ms/step #> Epoch 6/30 #> 1500/1500 - 2s - loss: 0.3023 - accuracy: 0.8873 - val_loss: 0.3929 - val_accuracy: 0.8644 - 2s/epoch - 2ms/step #> Epoch 7/30 #> 1500/1500 - 2s - loss: 0.2913 - accuracy: 0.8909 - val_loss: 0.3719 - val_accuracy: 0.8710 - 2s/epoch - 2ms/step #> Epoch 8/30 #> 1500/1500 - 2s - loss: 0.2811 - accuracy: 0.8940 - val_loss: 0.3495 - val_accuracy: 0.8792 - 2s/epoch - 2ms/step #> Epoch 9/30 #> 1500/1500 - 2s - loss: 0.2743 - accuracy: 0.8971 - val_loss: 0.3405 - val_accuracy: 0.8810 - 2s/epoch - 2ms/step #> Epoch 10/30 #> 1500/1500 - 2s - loss: 0.2665 - accuracy: 0.8996 - val_loss: 0.3728 - val_accuracy: 0.8781 - 2s/epoch - 2ms/step #> Epoch 11/30 #> 1500/1500 - 2s - loss: 0.2566 - accuracy: 0.9025 - val_loss: 0.3438 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step #> Epoch 12/30 #> 1500/1500 - 2s - loss: 0.2521 - accuracy: 0.9053 - val_loss: 0.3484 - val_accuracy: 0.8816 - 2s/epoch - 2ms/step #> Epoch 13/30 #> 1500/1500 - 2s - loss: 0.2464 - accuracy: 0.9075 - val_loss: 0.3808 - val_accuracy: 0.8798 - 2s/epoch - 2ms/step #> Epoch 14/30 #> 1500/1500 - 2s - loss: 0.2418 - accuracy: 0.9095 - val_loss: 0.3621 - val_accuracy: 0.8792 - 2s/epoch - 2ms/step #> Epoch 15/30 #> 1500/1500 - 2s - loss: 0.2371 - accuracy: 0.9115 - val_loss: 0.3720 - val_accuracy: 0.8802 - 2s/epoch - 2ms/step #> Epoch 16/30 #> 1500/1500 - 2s - loss: 0.2323 - accuracy: 0.9113 - val_loss: 0.4080 - val_accuracy: 0.8724 - 2s/epoch - 2ms/step #> Epoch 17/30 #> 1500/1500 - 2s - loss: 0.2270 - accuracy: 0.9149 - val_loss: 0.3700 - val_accuracy: 0.8837 - 2s/epoch - 2ms/step #> Epoch 18/30 #> 1500/1500 - 2s - loss: 0.2259 - accuracy: 0.9156 - val_loss: 0.3876 - val_accuracy: 0.8762 - 2s/epoch - 2ms/step #> Epoch 19/30 #> 1500/1500 - 2s - loss: 0.2188 - accuracy: 0.9176 - val_loss: 0.3985 - val_accuracy: 0.8790 - 2s/epoch - 2ms/step #> Epoch 20/30 #> 1500/1500 - 2s - loss: 0.2173 - accuracy: 0.9181 - val_loss: 0.3985 - val_accuracy: 0.8786 - 2s/epoch - 2ms/step #> Epoch 21/30 #> 1500/1500 - 2s - loss: 0.2157 - accuracy: 0.9178 - val_loss: 0.3897 - val_accuracy: 0.8780 - 2s/epoch - 2ms/step #> Epoch 22/30 #> 1500/1500 - 2s - loss: 0.2097 - accuracy: 0.9204 - val_loss: 0.4196 - val_accuracy: 0.8715 - 2s/epoch - 2ms/step #> Epoch 23/30 #> 1500/1500 - 2s - loss: 0.2041 - accuracy: 0.9219 - val_loss: 0.4004 - val_accuracy: 0.8847 - 2s/epoch - 2ms/step #> Epoch 24/30 #> 1500/1500 - 2s - loss: 0.2103 - accuracy: 0.9214 - val_loss: 0.3974 - val_accuracy: 0.8798 - 2s/epoch - 2ms/step #> Epoch 25/30 #> 1500/1500 - 2s - loss: 0.2015 - accuracy: 0.9237 - val_loss: 0.4226 - val_accuracy: 0.8752 - 2s/epoch - 2ms/step #> Epoch 26/30 #> 1500/1500 - 2s - loss: 0.1981 - accuracy: 0.9248 - val_loss: 0.4148 - val_accuracy: 0.8790 - 2s/epoch - 2ms/step #> Epoch 27/30 #> 1500/1500 - 2s - loss: 0.1968 - accuracy: 0.9256 - val_loss: 0.4284 - val_accuracy: 0.8794 - 2s/epoch - 2ms/step #> Epoch 28/30 #> 1500/1500 - 2s - loss: 0.1941 - accuracy: 0.9254 - val_loss: 0.4420 - val_accuracy: 0.8748 - 2s/epoch - 2ms/step #> Epoch 29/30 #> 1500/1500 - 2s - loss: 0.1895 - accuracy: 0.9277 - val_loss: 0.4702 - val_accuracy: 0.8709 - 2s/epoch - 2ms/step #> Epoch 30/30 #> 1500/1500 - 2s - loss: 0.1899 - accuracy: 0.9268 - val_loss: 0.4311 - val_accuracy: 0.8852 - 2s/epoch - 2ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.4695269  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.8785  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > view_runs_diff()"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"flags","dir":"Articles","previous_headings":"","what":"Flags","title":"Introduction","text":"Flags form run inputs, paramaterization. action just , modifying learning_rate, epochs units values script launching second run, can handled us guild_run() using flags interface. default, top-level assignments scalar literals R script identified guild run flags can modified per-run. can quickly see flags available R script passing --help-op (later). launch run different flag values, can : Now, inspect run sources view_runs_diff(), see source files associated run updated flag values, modified manually. flags interface useful hyperparamater optimization. ’s simplest, can just iterate set flag values want: wait = FALSE means guild_run() call launches run process returns immediately. easy way launch multiple training runs parallel. can view progress real-time outputs runs guild_view(), status (“training” “completed”). Alternatively, can pass multiple values flag, guild automatically expand combinations grid search. example, launch 4 training runs, combination flag values: precision, can pass dataframe flags values, row corresponding run.","code":"guild_run(\"fashion-mnist.R\", \"--help-op\") #> Usage: guild run [OPTIONS] fashion-mnist.R [FLAG]... #>  #> Use 'guild run --help' for a list of options. #>  #> Flags: #>   .fast          (default is yes) #>   batch_size     (default is 32.0) #>   epochs         (default is 30.0) #>   learning_rate  (default is 0.003) #>   units          (default is 128.0) for (learning_rate in c(0.001, 0.003))   guild_run(\"fashion-mnist.R\", c(learning_rate = learning_rate),             wait = FALSE) guild_run(\"fashion-mnist.R\",            flags = list(learning_rate = c(0.001, 0.003),                        units = c(128, 256))) #> INFO: [guild] Running trial 44719bd4ec224af1811a0660608b8caa: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=128.0) #> Replaced expression 'learning_rate <- 0.003' on line 23 with 'learning_rate <- 0.001' #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:33:24.601613: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/30 #> 1500/1500 - 3s - loss: 0.5166 - accuracy: 0.8189 - val_loss: 0.4251 - val_accuracy: 0.8492 - 3s/epoch - 2ms/step #> Epoch 2/30 #> 1500/1500 - 2s - loss: 0.3878 - accuracy: 0.8599 - val_loss: 0.3860 - val_accuracy: 0.8640 - 2s/epoch - 2ms/step #> Epoch 3/30 #> 1500/1500 - 2s - loss: 0.3431 - accuracy: 0.8754 - val_loss: 0.3767 - val_accuracy: 0.8679 - 2s/epoch - 2ms/step #> Epoch 4/30 #> 1500/1500 - 2s - loss: 0.3217 - accuracy: 0.8829 - val_loss: 0.3492 - val_accuracy: 0.8754 - 2s/epoch - 2ms/step #> Epoch 5/30 #> 1500/1500 - 2s - loss: 0.3028 - accuracy: 0.8886 - val_loss: 0.3318 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step #> Epoch 6/30 #> 1500/1500 - 2s - loss: 0.2873 - accuracy: 0.8946 - val_loss: 0.3329 - val_accuracy: 0.8806 - 2s/epoch - 2ms/step #> Epoch 7/30 #> 1500/1500 - 2s - loss: 0.2731 - accuracy: 0.8985 - val_loss: 0.3232 - val_accuracy: 0.8843 - 2s/epoch - 2ms/step #> Epoch 8/30 #> 1500/1500 - 2s - loss: 0.2618 - accuracy: 0.9036 - val_loss: 0.3225 - val_accuracy: 0.8841 - 2s/epoch - 2ms/step #> Epoch 9/30 #> 1500/1500 - 2s - loss: 0.2507 - accuracy: 0.9074 - val_loss: 0.3467 - val_accuracy: 0.8788 - 2s/epoch - 2ms/step #> Epoch 10/30 #> 1500/1500 - 2s - loss: 0.2416 - accuracy: 0.9096 - val_loss: 0.3379 - val_accuracy: 0.8817 - 2s/epoch - 2ms/step #> Epoch 11/30 #> 1500/1500 - 2s - loss: 0.2348 - accuracy: 0.9115 - val_loss: 0.3361 - val_accuracy: 0.8845 - 2s/epoch - 2ms/step #> Epoch 12/30 #> 1500/1500 - 2s - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.3221 - val_accuracy: 0.8889 - 2s/epoch - 2ms/step #> Epoch 13/30 #> 1500/1500 - 2s - loss: 0.2186 - accuracy: 0.9177 - val_loss: 0.3553 - val_accuracy: 0.8773 - 2s/epoch - 2ms/step #> Epoch 14/30 #> 1500/1500 - 2s - loss: 0.2115 - accuracy: 0.9204 - val_loss: 0.3300 - val_accuracy: 0.8880 - 2s/epoch - 2ms/step #> Epoch 15/30 #> 1500/1500 - 2s - loss: 0.2044 - accuracy: 0.9232 - val_loss: 0.3321 - val_accuracy: 0.8887 - 2s/epoch - 2ms/step #> Epoch 16/30 #> 1500/1500 - 2s - loss: 0.2003 - accuracy: 0.9249 - val_loss: 0.3278 - val_accuracy: 0.8903 - 2s/epoch - 2ms/step #> Epoch 17/30 #> 1500/1500 - 2s - loss: 0.1927 - accuracy: 0.9279 - val_loss: 0.3567 - val_accuracy: 0.8838 - 2s/epoch - 2ms/step #> Epoch 18/30 #> 1500/1500 - 2s - loss: 0.1883 - accuracy: 0.9290 - val_loss: 0.3552 - val_accuracy: 0.8858 - 2s/epoch - 2ms/step #> Epoch 19/30 #> 1500/1500 - 2s - loss: 0.1814 - accuracy: 0.9317 - val_loss: 0.3480 - val_accuracy: 0.8877 - 2s/epoch - 2ms/step #> Epoch 20/30 #> 1500/1500 - 2s - loss: 0.1788 - accuracy: 0.9321 - val_loss: 0.3517 - val_accuracy: 0.8882 - 2s/epoch - 2ms/step #> Epoch 21/30 #> 1500/1500 - 2s - loss: 0.1741 - accuracy: 0.9351 - val_loss: 0.3525 - val_accuracy: 0.8908 - 2s/epoch - 2ms/step #> Epoch 22/30 #> 1500/1500 - 2s - loss: 0.1678 - accuracy: 0.9375 - val_loss: 0.3745 - val_accuracy: 0.8857 - 2s/epoch - 2ms/step #> Epoch 23/30 #> 1500/1500 - 2s - loss: 0.1628 - accuracy: 0.9389 - val_loss: 0.3960 - val_accuracy: 0.8838 - 2s/epoch - 2ms/step #> Epoch 24/30 #> 1500/1500 - 2s - loss: 0.1605 - accuracy: 0.9403 - val_loss: 0.3679 - val_accuracy: 0.8885 - 2s/epoch - 2ms/step #> Epoch 25/30 #> 1500/1500 - 2s - loss: 0.1572 - accuracy: 0.9417 - val_loss: 0.3830 - val_accuracy: 0.8862 - 2s/epoch - 2ms/step #> Epoch 26/30 #> 1500/1500 - 2s - loss: 0.1521 - accuracy: 0.9434 - val_loss: 0.3732 - val_accuracy: 0.8918 - 2s/epoch - 2ms/step #> Epoch 27/30 #> 1500/1500 - 2s - loss: 0.1479 - accuracy: 0.9459 - val_loss: 0.3794 - val_accuracy: 0.8905 - 2s/epoch - 2ms/step #> Epoch 28/30 #> 1500/1500 - 2s - loss: 0.1461 - accuracy: 0.9452 - val_loss: 0.4029 - val_accuracy: 0.8858 - 2s/epoch - 2ms/step #> Epoch 29/30 #> 1500/1500 - 2s - loss: 0.1390 - accuracy: 0.9484 - val_loss: 0.3875 - val_accuracy: 0.8902 - 2s/epoch - 2ms/step #> Epoch 30/30 #> 1500/1500 - 2s - loss: 0.1377 - accuracy: 0.9494 - val_loss: 0.4272 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.4655154  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.8757  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial 7a9d1ce8b5c849b7bfde5fba78308253: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=256.0) #> Replaced expression 'units <- 128' on line 14 with 'units <- 256' #> Replaced expression 'learning_rate <- 0.003' on line 23 with 'learning_rate <- 0.001' #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:34:44.388413: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 256 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 256)                     200960       #>  dense (Dense)                      (None, 10)                      2570         #> ================================================================================ #> Total params: 203,530 #> Trainable params: 203,530 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/30 #> 1500/1500 - 3s - loss: 0.5037 - accuracy: 0.8212 - val_loss: 0.4364 - val_accuracy: 0.8453 - 3s/epoch - 2ms/step #> Epoch 2/30 #> 1500/1500 - 2s - loss: 0.3778 - accuracy: 0.8640 - val_loss: 0.3844 - val_accuracy: 0.8572 - 2s/epoch - 2ms/step #> Epoch 3/30 #> 1500/1500 - 2s - loss: 0.3363 - accuracy: 0.8761 - val_loss: 0.3637 - val_accuracy: 0.8690 - 2s/epoch - 2ms/step #> Epoch 4/30 #> 1500/1500 - 2s - loss: 0.3100 - accuracy: 0.8846 - val_loss: 0.3379 - val_accuracy: 0.8783 - 2s/epoch - 2ms/step #> Epoch 5/30 #> 1500/1500 - 2s - loss: 0.2895 - accuracy: 0.8925 - val_loss: 0.3268 - val_accuracy: 0.8817 - 2s/epoch - 2ms/step #> Epoch 6/30 #> 1500/1500 - 2s - loss: 0.2754 - accuracy: 0.8974 - val_loss: 0.3107 - val_accuracy: 0.8898 - 2s/epoch - 2ms/step #> Epoch 7/30 #> 1500/1500 - 2s - loss: 0.2631 - accuracy: 0.9017 - val_loss: 0.3072 - val_accuracy: 0.8887 - 2s/epoch - 2ms/step #> Epoch 8/30 #> 1500/1500 - 2s - loss: 0.2496 - accuracy: 0.9054 - val_loss: 0.3356 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step #> Epoch 9/30 #> 1500/1500 - 2s - loss: 0.2377 - accuracy: 0.9116 - val_loss: 0.3033 - val_accuracy: 0.8913 - 2s/epoch - 2ms/step #> Epoch 10/30 #> 1500/1500 - 2s - loss: 0.2291 - accuracy: 0.9147 - val_loss: 0.3249 - val_accuracy: 0.8877 - 2s/epoch - 2ms/step #> Epoch 11/30 #> 1500/1500 - 2s - loss: 0.2213 - accuracy: 0.9180 - val_loss: 0.3128 - val_accuracy: 0.8919 - 2s/epoch - 2ms/step #> Epoch 12/30 #> 1500/1500 - 4s - loss: 0.2120 - accuracy: 0.9193 - val_loss: 0.3173 - val_accuracy: 0.8898 - 4s/epoch - 2ms/step #> Epoch 13/30 #> 1500/1500 - 3s - loss: 0.2055 - accuracy: 0.9225 - val_loss: 0.3260 - val_accuracy: 0.8908 - 3s/epoch - 2ms/step #> Epoch 14/30 #> 1500/1500 - 3s - loss: 0.1976 - accuracy: 0.9270 - val_loss: 0.3312 - val_accuracy: 0.8820 - 3s/epoch - 2ms/step #> Epoch 15/30 #> 1500/1500 - 2s - loss: 0.1921 - accuracy: 0.9279 - val_loss: 0.3353 - val_accuracy: 0.8920 - 2s/epoch - 2ms/step #> Epoch 16/30 #> 1500/1500 - 2s - loss: 0.1834 - accuracy: 0.9300 - val_loss: 0.3267 - val_accuracy: 0.8913 - 2s/epoch - 1ms/step #> Epoch 17/30 #> 1500/1500 - 2s - loss: 0.1777 - accuracy: 0.9337 - val_loss: 0.3416 - val_accuracy: 0.8928 - 2s/epoch - 1ms/step #> Epoch 18/30 #> 1500/1500 - 2s - loss: 0.1722 - accuracy: 0.9344 - val_loss: 0.3472 - val_accuracy: 0.8862 - 2s/epoch - 1ms/step #> Epoch 19/30 #> 1500/1500 - 2s - loss: 0.1670 - accuracy: 0.9370 - val_loss: 0.3512 - val_accuracy: 0.8918 - 2s/epoch - 1ms/step #> Epoch 20/30 #> 1500/1500 - 2s - loss: 0.1633 - accuracy: 0.9379 - val_loss: 0.3582 - val_accuracy: 0.8891 - 2s/epoch - 1ms/step #> Epoch 21/30 #> 1500/1500 - 2s - loss: 0.1549 - accuracy: 0.9418 - val_loss: 0.3556 - val_accuracy: 0.8902 - 2s/epoch - 1ms/step #> Epoch 22/30 #> 1500/1500 - 2s - loss: 0.1532 - accuracy: 0.9429 - val_loss: 0.3514 - val_accuracy: 0.8946 - 2s/epoch - 1ms/step #> Epoch 23/30 #> 1500/1500 - 2s - loss: 0.1477 - accuracy: 0.9445 - val_loss: 0.3597 - val_accuracy: 0.8936 - 2s/epoch - 1ms/step #> Epoch 24/30 #> 1500/1500 - 2s - loss: 0.1414 - accuracy: 0.9472 - val_loss: 0.3647 - val_accuracy: 0.8929 - 2s/epoch - 1ms/step #> Epoch 25/30 #> 1500/1500 - 2s - loss: 0.1394 - accuracy: 0.9473 - val_loss: 0.3681 - val_accuracy: 0.8921 - 2s/epoch - 1ms/step #> Epoch 26/30 #> 1500/1500 - 2s - loss: 0.1356 - accuracy: 0.9497 - val_loss: 0.4043 - val_accuracy: 0.8823 - 2s/epoch - 1ms/step #> Epoch 27/30 #> 1500/1500 - 2s - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.4060 - val_accuracy: 0.8916 - 2s/epoch - 1ms/step #> Epoch 28/30 #> 1500/1500 - 2s - loss: 0.1295 - accuracy: 0.9511 - val_loss: 0.3764 - val_accuracy: 0.8955 - 2s/epoch - 1ms/step #> Epoch 29/30 #> 1500/1500 - 2s - loss: 0.1259 - accuracy: 0.9521 - val_loss: 0.3850 - val_accuracy: 0.8933 - 2s/epoch - 1ms/step #> Epoch 30/30 #> 1500/1500 - 2s - loss: 0.1234 - accuracy: 0.9532 - val_loss: 0.4001 - val_accuracy: 0.8901 - 2s/epoch - 1ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.4463007  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.8833  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial 157f9b69b3f748ae87300775d7b0d87a: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=128.0) #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:36:02.988859: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/30 #> 1500/1500 - 3s - loss: 0.4985 - accuracy: 0.8216 - val_loss: 0.4405 - val_accuracy: 0.8437 - 3s/epoch - 2ms/step #> Epoch 2/30 #> 1500/1500 - 2s - loss: 0.3849 - accuracy: 0.8607 - val_loss: 0.3994 - val_accuracy: 0.8573 - 2s/epoch - 1ms/step #> Epoch 3/30 #> 1500/1500 - 2s - loss: 0.3534 - accuracy: 0.8704 - val_loss: 0.3535 - val_accuracy: 0.8743 - 2s/epoch - 1ms/step #> Epoch 4/30 #> 1500/1500 - 2s - loss: 0.3341 - accuracy: 0.8758 - val_loss: 0.3669 - val_accuracy: 0.8682 - 2s/epoch - 1ms/step #> Epoch 5/30 #> 1500/1500 - 2s - loss: 0.3147 - accuracy: 0.8842 - val_loss: 0.3524 - val_accuracy: 0.8770 - 2s/epoch - 1ms/step #> Epoch 6/30 #> 1500/1500 - 2s - loss: 0.3026 - accuracy: 0.8879 - val_loss: 0.3437 - val_accuracy: 0.8801 - 2s/epoch - 1ms/step #> Epoch 7/30 #> 1500/1500 - 2s - loss: 0.2895 - accuracy: 0.8919 - val_loss: 0.3572 - val_accuracy: 0.8765 - 2s/epoch - 1ms/step #> Epoch 8/30 #> 1500/1500 - 2s - loss: 0.2789 - accuracy: 0.8956 - val_loss: 0.3677 - val_accuracy: 0.8733 - 2s/epoch - 1ms/step #> Epoch 9/30 #> 1500/1500 - 2s - loss: 0.2740 - accuracy: 0.8982 - val_loss: 0.3506 - val_accuracy: 0.8753 - 2s/epoch - 1ms/step #> Epoch 10/30 #> 1500/1500 - 2s - loss: 0.2660 - accuracy: 0.8999 - val_loss: 0.3672 - val_accuracy: 0.8788 - 2s/epoch - 1ms/step #> Epoch 11/30 #> 1500/1500 - 2s - loss: 0.2587 - accuracy: 0.9020 - val_loss: 0.3465 - val_accuracy: 0.8864 - 2s/epoch - 1ms/step #> Epoch 12/30 #> 1500/1500 - 2s - loss: 0.2540 - accuracy: 0.9047 - val_loss: 0.3694 - val_accuracy: 0.8777 - 2s/epoch - 1ms/step #> Epoch 13/30 #> 1500/1500 - 2s - loss: 0.2467 - accuracy: 0.9090 - val_loss: 0.3703 - val_accuracy: 0.8788 - 2s/epoch - 1ms/step #> Epoch 14/30 #> 1500/1500 - 2s - loss: 0.2441 - accuracy: 0.9084 - val_loss: 0.3538 - val_accuracy: 0.8842 - 2s/epoch - 1ms/step #> Epoch 15/30 #> 1500/1500 - 2s - loss: 0.2348 - accuracy: 0.9123 - val_loss: 0.3686 - val_accuracy: 0.8781 - 2s/epoch - 1ms/step #> Epoch 16/30 #> 1500/1500 - 2s - loss: 0.2297 - accuracy: 0.9135 - val_loss: 0.3826 - val_accuracy: 0.8819 - 2s/epoch - 1ms/step #> Epoch 17/30 #> 1500/1500 - 2s - loss: 0.2300 - accuracy: 0.9129 - val_loss: 0.3652 - val_accuracy: 0.8838 - 2s/epoch - 1ms/step #> Epoch 18/30 #> 1500/1500 - 2s - loss: 0.2193 - accuracy: 0.9169 - val_loss: 0.3649 - val_accuracy: 0.8853 - 2s/epoch - 1ms/step #> Epoch 19/30 #> 1500/1500 - 2s - loss: 0.2188 - accuracy: 0.9181 - val_loss: 0.3805 - val_accuracy: 0.8829 - 2s/epoch - 1ms/step #> Epoch 20/30 #> 1500/1500 - 2s - loss: 0.2146 - accuracy: 0.9176 - val_loss: 0.3850 - val_accuracy: 0.8820 - 2s/epoch - 1ms/step #> Epoch 21/30 #> 1500/1500 - 2s - loss: 0.2102 - accuracy: 0.9208 - val_loss: 0.3870 - val_accuracy: 0.8815 - 2s/epoch - 1ms/step #> Epoch 22/30 #> 1500/1500 - 2s - loss: 0.2061 - accuracy: 0.9224 - val_loss: 0.3888 - val_accuracy: 0.8796 - 2s/epoch - 1ms/step #> Epoch 23/30 #> 1500/1500 - 2s - loss: 0.2021 - accuracy: 0.9237 - val_loss: 0.3889 - val_accuracy: 0.8907 - 2s/epoch - 2ms/step #> Epoch 24/30 #> 1500/1500 - 2s - loss: 0.2000 - accuracy: 0.9240 - val_loss: 0.3891 - val_accuracy: 0.8892 - 2s/epoch - 1ms/step #> Epoch 25/30 #> 1500/1500 - 2s - loss: 0.1975 - accuracy: 0.9260 - val_loss: 0.4059 - val_accuracy: 0.8868 - 2s/epoch - 1ms/step #> Epoch 26/30 #> 1500/1500 - 2s - loss: 0.1961 - accuracy: 0.9261 - val_loss: 0.4077 - val_accuracy: 0.8855 - 2s/epoch - 1ms/step #> Epoch 27/30 #> 1500/1500 - 2s - loss: 0.1926 - accuracy: 0.9265 - val_loss: 0.4143 - val_accuracy: 0.8770 - 2s/epoch - 1ms/step #> Epoch 28/30 #> 1500/1500 - 2s - loss: 0.1902 - accuracy: 0.9284 - val_loss: 0.4149 - val_accuracy: 0.8893 - 2s/epoch - 1ms/step #> Epoch 29/30 #> 1500/1500 - 2s - loss: 0.1834 - accuracy: 0.9306 - val_loss: 0.4563 - val_accuracy: 0.8722 - 2s/epoch - 1ms/step #> Epoch 30/30 #> 1500/1500 - 2s - loss: 0.1837 - accuracy: 0.9311 - val_loss: 0.4241 - val_accuracy: 0.8818 - 2s/epoch - 1ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.4663589  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.8736  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial 4ad73fb75e594fab97369480d01455c1: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=256.0) #> Replaced expression 'units <- 128' on line 14 with 'units <- 256' #> Replaced expression '.fast <- TRUE' on line 38 with '.fast <- FALSE' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 13:37:15.111377: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 256 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 256)                     200960       #>  dense (Dense)                      (None, 10)                      2570         #> ================================================================================ #> Total params: 203,530 #> Trainable params: 203,530 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- FALSE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/30 #> 1500/1500 - 3s - loss: 0.5009 - accuracy: 0.8208 - val_loss: 0.4256 - val_accuracy: 0.8424 - 3s/epoch - 2ms/step #> Epoch 2/30 #> 1500/1500 - 2s - loss: 0.3857 - accuracy: 0.8580 - val_loss: 0.3752 - val_accuracy: 0.8622 - 2s/epoch - 2ms/step #> Epoch 3/30 #> 1500/1500 - 2s - loss: 0.3519 - accuracy: 0.8702 - val_loss: 0.3709 - val_accuracy: 0.8632 - 2s/epoch - 2ms/step #> Epoch 4/30 #> 1500/1500 - 2s - loss: 0.3298 - accuracy: 0.8790 - val_loss: 0.3787 - val_accuracy: 0.8622 - 2s/epoch - 2ms/step #> Epoch 5/30 #> 1500/1500 - 2s - loss: 0.3112 - accuracy: 0.8847 - val_loss: 0.3416 - val_accuracy: 0.8794 - 2s/epoch - 1ms/step #> Epoch 6/30 #> 1500/1500 - 2s - loss: 0.2998 - accuracy: 0.8883 - val_loss: 0.3408 - val_accuracy: 0.8814 - 2s/epoch - 1ms/step #> Epoch 7/30 #> 1500/1500 - 2s - loss: 0.2861 - accuracy: 0.8923 - val_loss: 0.3429 - val_accuracy: 0.8799 - 2s/epoch - 1ms/step #> Epoch 8/30 #> 1500/1500 - 2s - loss: 0.2779 - accuracy: 0.8958 - val_loss: 0.3835 - val_accuracy: 0.8713 - 2s/epoch - 1ms/step #> Epoch 9/30 #> 1500/1500 - 2s - loss: 0.2686 - accuracy: 0.8993 - val_loss: 0.3509 - val_accuracy: 0.8798 - 2s/epoch - 1ms/step #> Epoch 10/30 #> 1500/1500 - 2s - loss: 0.2652 - accuracy: 0.9009 - val_loss: 0.3598 - val_accuracy: 0.8789 - 2s/epoch - 1ms/step #> Epoch 11/30 #> 1500/1500 - 2s - loss: 0.2515 - accuracy: 0.9057 - val_loss: 0.3538 - val_accuracy: 0.8773 - 2s/epoch - 1ms/step #> Epoch 12/30 #> 1500/1500 - 2s - loss: 0.2526 - accuracy: 0.9058 - val_loss: 0.3770 - val_accuracy: 0.8724 - 2s/epoch - 2ms/step #> Epoch 13/30 #> 1500/1500 - 2s - loss: 0.2442 - accuracy: 0.9087 - val_loss: 0.3619 - val_accuracy: 0.8786 - 2s/epoch - 2ms/step #> Epoch 14/30 #> 1500/1500 - 2s - loss: 0.2396 - accuracy: 0.9091 - val_loss: 0.3741 - val_accuracy: 0.8780 - 2s/epoch - 1ms/step #> Epoch 15/30 #> 1500/1500 - 2s - loss: 0.2323 - accuracy: 0.9136 - val_loss: 0.3608 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step #> Epoch 16/30 #> 1500/1500 - 2s - loss: 0.2269 - accuracy: 0.9147 - val_loss: 0.3554 - val_accuracy: 0.8869 - 2s/epoch - 2ms/step #> Epoch 17/30 #> 1500/1500 - 2s - loss: 0.2214 - accuracy: 0.9172 - val_loss: 0.3672 - val_accuracy: 0.8863 - 2s/epoch - 1ms/step #> Epoch 18/30 #> 1500/1500 - 2s - loss: 0.2212 - accuracy: 0.9162 - val_loss: 0.3642 - val_accuracy: 0.8790 - 2s/epoch - 1ms/step #> Epoch 19/30 #> 1500/1500 - 2s - loss: 0.2173 - accuracy: 0.9185 - val_loss: 0.4110 - val_accuracy: 0.8793 - 2s/epoch - 2ms/step #> Epoch 20/30 #> 1500/1500 - 2s - loss: 0.2095 - accuracy: 0.9214 - val_loss: 0.3777 - val_accuracy: 0.8870 - 2s/epoch - 1ms/step #> Epoch 21/30 #> 1500/1500 - 2s - loss: 0.2110 - accuracy: 0.9210 - val_loss: 0.3732 - val_accuracy: 0.8868 - 2s/epoch - 1ms/step #> Epoch 22/30 #> 1500/1500 - 2s - loss: 0.2041 - accuracy: 0.9226 - val_loss: 0.3829 - val_accuracy: 0.8865 - 2s/epoch - 2ms/step #> Epoch 23/30 #> 1500/1500 - 2s - loss: 0.2014 - accuracy: 0.9241 - val_loss: 0.3810 - val_accuracy: 0.8850 - 2s/epoch - 1ms/step #> Epoch 24/30 #> 1500/1500 - 2s - loss: 0.1973 - accuracy: 0.9255 - val_loss: 0.4041 - val_accuracy: 0.8841 - 2s/epoch - 2ms/step #> Epoch 25/30 #> 1500/1500 - 2s - loss: 0.1990 - accuracy: 0.9256 - val_loss: 0.4017 - val_accuracy: 0.8832 - 2s/epoch - 1ms/step #> Epoch 26/30 #> 1500/1500 - 2s - loss: 0.1904 - accuracy: 0.9276 - val_loss: 0.4150 - val_accuracy: 0.8841 - 2s/epoch - 1ms/step #> Epoch 27/30 #> 1500/1500 - 2s - loss: 0.1908 - accuracy: 0.9280 - val_loss: 0.4381 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step #> Epoch 28/30 #> 1500/1500 - 2s - loss: 0.1875 - accuracy: 0.9283 - val_loss: 0.4197 - val_accuracy: 0.8892 - 2s/epoch - 1ms/step #> Epoch 29/30 #> 1500/1500 - 2s - loss: 0.1866 - accuracy: 0.9296 - val_loss: 0.4281 - val_accuracy: 0.8845 - 2s/epoch - 1ms/step #> Epoch 30/30 #> 1500/1500 - 2s - loss: 0.1798 - accuracy: 0.9319 - val_loss: 0.4349 - val_accuracy: 0.8882 - 2s/epoch - 2ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 0.4721423  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.8751  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > flags_df <- expand.grid(learning_rate = c(0.001, 0.003),                         units = c(128, 256)) flags_df #>   learning_rate units #> 1         0.001   128 #> 2         0.003   128 #> 3         0.001   256 #> 4         0.003   256 guild_run(\"fashion-mnist.R\", flags = flags_df)"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"flag-annotations","dir":"Articles","previous_headings":"Flags","what":"Flag annotations","title":"Introduction","text":"can optionally supply additional metadata individual flags placing hashpipe yaml annotations flag expression. example, can update “fashion-mnist.R” script following lines: Now, descriptions constraints appear --help-op related locations.","code":"#| description: size of first layer. #| min: 16 #| max: 256 units <- 32  #| description: Activation function to use. #| choices: [relu, sigmoid, tanh] activation <- \"relu\""},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"flag-destinations","dir":"Articles","previous_headings":"Flags","what":"Flag destinations","title":"Introduction","text":"project grows, ’s helpful able move flag definitions main R script. , can include flags-dest frontmatter R script, specifying file path (relative project directory) file guild place flag values. can read flags using source() similar. YAML files also supported flags destination:","code":"#| flags-dest: ./flags.R  FLAGS <- envir::include(\"flags.R\", new.env()) #| flags-dest: ./flags.yml  FLAGS <- yaml::read_yaml(\"flags.yml\")"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"retreiving-run-flags","dir":"Articles","previous_headings":"Flags","what":"Retreiving Run Flags","title":"Introduction","text":"flags flag values associated runs returned ls_runs() nested dataframe flags.","code":"runs <- ls_runs() runs %>%   select(shortId, flags) #%>% tidyr::unnest(flags, names_sep = \"_\") #> # A tibble: 7 × 2 #>   shortId  flags$.fast $batch_size $epochs $learning_rate $units #>   <chr>    <lgl>             <dbl>   <dbl>          <dbl>  <dbl> #> 1 4ad73fb7 FALSE                32      30          0.003    256 #> 2 157f9b69 FALSE                32      30          0.003    128 #> 3 7a9d1ce8 FALSE                32      30          0.001    256 #> 4 44719bd4 FALSE                32      30          0.001    128 #> 5 ac078248 FALSE                32      30          0.001    256 #> 6 1d6e49cc FALSE                32      30          0.003    128 #> 7 f4375fbc FALSE                32      20          0.001     64"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"scalars","dir":"Articles","previous_headings":"","what":"Scalars","title":"Introduction","text":"counterpart run flags run scalars. flags type run input, scalars run outputs identified Guild meaningful track. see guild automatically identified test_accuracy test_loss run scalar outputs. default, lines printed standard output run patten \"key: numeric-value\" recorded guild scalars. printing values scalar key multiple times run (e.g, loss training loop), sure also print step scalar , enable guild track history (enable visualization run metrics tensorboard). Alternatively, run process produces tfevent records directly (e.g., keras::callback_tensorboard(\"./logs\")), automatically identified guild run scalars, included ls_runs() (guild_view(), tensorboard run views). ls_runs() default returns summary run scalars, full scalar history can also accessed R directly:","code":"runs %>%   select(shortId, scalars) #> # A tibble: 7 × 2 #>   shortId  scalars           #>   <chr>    <list>            #> 1 4ad73fb7 <tibble [2 × 14]> #> 2 157f9b69 <tibble [2 × 14]> #> 3 7a9d1ce8 <tibble [2 × 14]> #> 4 44719bd4 <tibble [2 × 14]> #> 5 ac078248 <tibble [2 × 14]> #> 6 1d6e49cc <tibble [2 × 14]> #> 7 f4375fbc <tibble [2 × 14]>  glimpse(runs$scalars[[1]]) #> Rows: 2 #> Columns: 14 #> $ run        <chr> \"4ad73fb75e594fab97369480d01455c1\", \"4ad73fb75e594fab973694… #> $ prefix     <chr> \".guild\", \".guild\" #> $ tag        <chr> \"test_accuracy\", \"test_loss\" #> $ first_val  <dbl> 0.8751000, 0.4721423 #> $ first_step <int> 0, 0 #> $ last_val   <dbl> 0.8751000, 0.4721423 #> $ last_step  <int> 0, 0 #> $ min_val    <dbl> 0.8751000, 0.4721423 #> $ min_step   <int> 0, 0 #> $ max_val    <dbl> 0.8751000, 0.4721423 #> $ max_step   <int> 0, 0 #> $ avg_val    <dbl> 0.8751000, 0.4721423 #> $ total      <dbl> 0.8751000, 0.4721423 #> $ count      <int> 1, 1 ls_runs(scalars = TRUE) #> # A tibble: 14 × 5 #>    run                              path   tag           value  step #>    <chr>                            <chr>  <chr>         <dbl> <int> #>  1 4ad73fb75e594fab97369480d01455c1 .guild test_loss     0.472     0 #>  2 4ad73fb75e594fab97369480d01455c1 .guild test_accuracy 0.875     0 #>  3 157f9b69b3f748ae87300775d7b0d87a .guild test_loss     0.466     0 #>  4 157f9b69b3f748ae87300775d7b0d87a .guild test_accuracy 0.874     0 #>  5 7a9d1ce8b5c849b7bfde5fba78308253 .guild test_loss     0.446     0 #>  6 7a9d1ce8b5c849b7bfde5fba78308253 .guild test_accuracy 0.883     0 #>  7 44719bd4ec224af1811a0660608b8caa .guild test_loss     0.466     0 #>  8 44719bd4ec224af1811a0660608b8caa .guild test_accuracy 0.876     0 #>  9 ac078248d35b4b5d99815be775c40c0f .guild test_loss     0.449     0 #> 10 ac078248d35b4b5d99815be775c40c0f .guild test_accuracy 0.884     0 #> 11 1d6e49cc32774746bf801cbbed187a51 .guild test_loss     0.470     0 #> 12 1d6e49cc32774746bf801cbbed187a51 .guild test_accuracy 0.878     0 #> 13 f4375fbcfa6b4158b9f8017d87affad7 .guild test_loss     0.369     0 #> 14 f4375fbcfa6b4158b9f8017d87affad7 .guild test_accuracy 0.882     0"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"using-flags-and-scalars-together","dir":"Articles","previous_headings":"","what":"Using Flags and Scalars Together","title":"Introduction","text":"can use guild explore impact units test_accuracy. can see compare run flags run scalars R:","code":"units <- (2 ^ (4:11)) %>% c(diff(., 2)) %>% sort() units  #>  [1]   16   32   48   64   96  128  192  256  384  512  768 1024 1536 2048 guild_run(\"fashion-mnist.R\",            flags = list(units = units),           echo = FALSE) #> Error in writeLines(out) : can only write character objects runs <- ls_runs(paste0(\"1:\", length(units))) # last 8 runs  df <- runs %>%   select(flags, scalars) %>%   rowwise() %>%   mutate(across(scalars, function(run_scalars_df) {     run_scalars_df %>%       select(tag, last_val) %>%       tidyr::pivot_wider(names_from = tag,                          values_from = last_val)   })) %>%   tidyr::unnest(c(flags, scalars)) %>%   arrange(units)  df #> # A tibble: 14 × 7 #>    .fast batch_size epochs learning_rate units test_accuracy test_loss #>    <lgl>      <dbl>  <dbl>         <dbl> <dbl>         <dbl>     <dbl> #>  1 FALSE         32     30         0.003    16         0.847     0.459 #>  2 FALSE         32     30         0.003    32         0.860     0.455 #>  3 FALSE         32     30         0.003    48         0.873     0.438 #>  4 FALSE         32     30         0.003    64         0.878     0.443 #>  5 FALSE         32     30         0.003    96         0.878     0.491 #>  6 FALSE         32     30         0.003   128         0.877     0.450 #>  7 FALSE         32     30         0.003   192         0.876     0.472 #>  8 FALSE         32     30         0.003   256         0.882     0.473 #>  9 FALSE         32     30         0.003   384         0.882     0.438 #> 10 FALSE         32     30         0.003   512         0.880     0.476 #> 11 FALSE         32     30         0.003   768         0.870     0.505 #> 12 FALSE         32     30         0.003  1024         0.874     0.464 #> 13 FALSE         32     30         0.003  1536         0.865     0.543 #> 14 FALSE         32     30         0.003  2048         0.878     0.505 library(ggplot2) ggplot(df, aes(x = units, y = test_accuracy)) +   geom_point() + geom_smooth()"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"addin","dir":"Articles","previous_headings":"Using Flags and Scalars Together","what":"Addin","title":"Introduction","text":"guildai package installs RStudio IDE addin provides quick access frequently used functions Addins menu: Note can use Tools -> Modify Keyboard Shortcuts within RStudio assign keyboard shortcut one addin commands.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"background-training","dir":"Articles","previous_headings":"Using Flags and Scalars Together","what":"Background Training","title":"Introduction","text":"Since training runs can become quite lengthy, ’s often useful run background order keep R console free work. can launch guild run without blocking R console specifying guild_run(wait = FALSE) call. can view real-time outputs run(s) using guild_view(). Alternatively, can launch training runs terminal pane: running within RStudio can course use system terminal window background training.","code":"Rscript -e 'guildai::guild_run(\"train.R\")'"},{"path":"https://t-kalinowski.github.io/guildai-r/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tomasz Kalinowski. Author, copyright holder, maintainer.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalinowski T (2022). guildai: R interface guildai. R package version 0.0.0.9001, https://t-kalinowski.github.io/guildai-r/.","code":"@Manual{,   title = {guildai: R interface to guildai},   author = {Tomasz Kalinowski},   year = {2022},   note = {R package version 0.0.0.9001},   url = {https://t-kalinowski.github.io/guildai-r/}, }"},{"path":"https://t-kalinowski.github.io/guildai-r/index.html","id":"guildai","dir":"","previous_headings":"","what":"R interface to guildai","title":"R interface to guildai","text":"guildai provides suite tools tracking, visualizing, managing training runs experiments. {guildai} R package successor {tfruns} package designed work machine learning framework (even framework ). lets : Track hyperparameters, metrics, output, source code every training run. Compare hyperparmaeters metrics across runs find best performing model. Automatically generate reports visualize individual training runs comparisons runs. changes source code required.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R interface to guildai","text":"can install development version guildai Github :","code":"# install.packages(\"remotes\") remotes::install_github(\"t-kalinowski/guildai-r\") guildai::install_guild()"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch a guild run — guild_run","title":"Launch a guild run — guild_run","text":"Launch guild run","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch a guild run — guild_run","text":"","code":"guild_run(   opspec = \"train.R\",   flags = NULL,   ...,   wait = TRUE,   label = NULL,   tags = NULL,   echo = wait )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch a guild run — guild_run","text":"opspec typically path R script, scalar string guild recognizes valid opspec. flags - named list vector like `c(noise = .3, dropout = .4)` - scalar string like `\"noise=.3 dropout=.4\"` - dataframe flags batch runs ... Arguments passed base::system2 command system command invoked, character string. args character vector arguments command. stdout,stderr output stdout     stderr sent.  Possible values \"\", R     console (default), NULL FALSE (discard output),     TRUE (capture output character vector)     character string naming file. stdin input diverted?  \"\" means default,     alternatively character string naming file.  Ignored     input supplied. input character vector supplied, copied one     string per line temporary file, standard input     command redirected file. env character vector name=value strings set environment     variables. timeout timeout seconds, ignored 0.  limit     elapsed time running command separate process.   Fractions     seconds ignored. minimized,invisible arguments accepted Windows     ignored platform, warning. wait whether wait run finish label, tags optional strings used label tag experiments. echo whether output run shown current R console. Note, effect whether expressions echoed guild run stdout.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch a guild run — guild_run","text":"return value `system2()`, invisibly. function   primarily called side effect.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch Guild Viewer — guild_view","title":"Launch Guild Viewer — guild_view","text":"Launch Guild Viewer","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch Guild Viewer — guild_view","text":"","code":"guild_view(..., wait = FALSE)"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch Guild Viewer — guild_view","text":"... passed `guild` binary wait whether block R console application active.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":null,"dir":"Reference","previous_headings":"","what":"Install guildai core — install_guild","title":"Install guildai core — install_guild","text":"installs `guild` executable use package.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install guildai core — install_guild","text":"","code":"install_guild(   guildai = \"https://api.github.com/repos/guildai/guildai/tarball/HEAD\",   python = find_python() )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install guildai core — install_guild","text":"guildai character vector passed directly `pip install`. install release version guildai, can `\"guildai\"`. python path python binary, used create private venv.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install guildai core — install_guild","text":"path guild binary","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install guildai core — install_guild","text":"","code":"# install_guild(c(\"-e\", \"~/guild/guildai\")) # install_guild(\"~/guildai\", reticulate::install_python()) # install_guild(\"https://api.github.com/repos/guildai/guildai/tarball/HEAD\") # install_guild( #   guildai = \"https://api.github.com/repos/guildai/guildai/tarball/HEAD\", #   python = reticulate::install_python()) #"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":null,"dir":"Reference","previous_headings":"","what":"Is code executing in the context of a guild run? — is_run_active","title":"Is code executing in the context of a guild run? — is_run_active","text":"code executing context guild run?","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is code executing in the context of a guild run? — is_run_active","text":"","code":"is_run_active()"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is code executing in the context of a guild run? — is_run_active","text":"Boolean","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":null,"dir":"Reference","previous_headings":"","what":"list guild runs — ls_runs","title":"list guild runs — ls_runs","text":"list guild runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list guild runs — ls_runs","text":"","code":"ls_runs(..., full = FALSE, scalars = FALSE)"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"list guild runs — ls_runs","text":"... additional arguments passed `guild api runs`. Try `\"--help\"` see options. full Whether include available run info. scalars Wheter export scalars requested runs instead.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"list guild runs — ls_runs","text":"dataframe runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Render a Run Summary Report — view_run_report","title":"Render a Run Summary Report — view_run_report","text":"Render Run Summary Report","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render a Run Summary Report — view_run_report","text":"","code":"view_run_report(   id = ls_runs(\"1\")$id,   output_dir = file.path(tempdir(), id),   template = system.file(\"templates/view-run.qmd\", package = \"guildai\"),   viewer = getOption(\"guildai.viewer\"),   ... )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render a Run Summary Report — view_run_report","text":"id run id. Defaults latest run. output_dir directory place rendered document. template path parameterized quarto document. viewer Viewer display training run information within (default internal page viewer available, otherwise R session default web browser, `utils::browseURL()`). ... passed `quarto::quarto_render()`","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Render a Run Summary Report — view_run_report","text":"path generated html, invisibly","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"compare runs — view_runs_diff","title":"compare runs — view_runs_diff","text":"compare runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compare runs — view_runs_diff","text":"","code":"view_runs_diff(   ids = ls_runs(\"1:2\")$id,   output_dir = file.path(tempdir(), paste(ids, collapse = \"-\")),   template = system.file(\"templates/compare-runs.qmd\", package = \"guildai\"),   viewer = getOption(\"guildai.viewer\"),   ... )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compare runs — view_runs_diff","text":"ids, length 2 character vector run ids output_dir place rendered html template report template viewer Viewer display training run information within (default internal page viewer available, otherwise R session default web browser, `utils::browseURL()`). ... passed `quarto::quarto_render()`","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"compare runs — view_runs_diff","text":"path generated html, invisibly","code":""}]

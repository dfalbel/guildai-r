[{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Introduction","text":"R package provides interface (guildai core)[https://guild.ai/]. R package install guildai core first use, can call install_guild() customize installation. can install guildai package CRAN follows: {guildai} can used machine learning framework, even framework . introductory example, ’ll start Keras model applied fashion mnist dataset. ’ve used Keras R want follow along machine, can install like :","code":"install.packages(\"guildai\") guildai::install_guild() install.packages(\"keras\") library(keras) install_keras()"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"training","dir":"Articles","previous_headings":"","what":"Training","title":"Introduction","text":"start, ’ll setup sample project folder one script. training script looks like: train model guildai, just use guild_run() function place source() function execute R script. example: can source script R console source(\"fashion-mnist.R\"), run Terminal Rscript fashion-mnist.R. can run using guild_run(): default, output stream run shown R console. launching run, can launch application view runs guild_view(). Guild View application, can also launch tensorboard. can also retrieve data frame information run ls_runs(): ls_runs() returns data.frame information runs. sample project, ’ve launched one run, ls_runs() returns 1-row dataframe. Importantly, information run stored plain files filesystem. guild_view() ls_runs() provide two convenient ways gather present information runs. run can also used generate summary report, paramaterized quarto document:","code":"file.copy(system.file(\"examples/fashion-mnist.R\", package = \"guildai\"),           \".\", overwrite = TRUE) #> [1] TRUE library(keras)  # Prepare data ---- fashion_mnist <- dataset_fashion_mnist()  c(train_images, train_labels) %<-% fashion_mnist$train c(test_images, test_labels) %<-% fashion_mnist$test  train_images <- train_images / 255  test_images <- test_images / 255  # Define model ----  units <- 64  model <- keras_model_sequential(input_shape = c(28, 28)) model %>%   layer_flatten() %>%   layer_dense(units = units, activation = 'relu') %>%   layer_dense(units = 10, activation = 'softmax')   learning_rate <- 0.001  model %>% compile(   optimizer = optimizer_adam(learning_rate),   loss = 'sparse_categorical_crossentropy',   metrics = c('accuracy') )  model  # Fit model ----  batch_size <- 32 epochs <- 20  .fast <- TRUE if (.fast) {   n <- 1:20   train_images %<>% { .[n, ,] }   test_images %<>% { .[n, ,] }   test_labels %<>% { .[n] }   train_labels %<>% { .[n] }   epochs <- 2 }  history <- model %>%   fit(train_images, train_labels,       validation_split = 0.2,       batch_size = batch_size,       epochs = epochs,       verbose = 2)  plot(history)  # Evaluate model ----  score <- model %>%   evaluate(test_images, test_labels,            verbose = 0) %>%   as.list()  cat('test_loss:', score$loss, \"\\n\") cat('test_accuracy:', score$accuracy, \"\\n\")  # save_model_tf(model, \"model.keras\") # saveRDS(history, \"history.rds\") guild_run(\"fashion-mnist.R\") #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:10:14.683809: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 64 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 64)                      50240        #>  dense (Dense)                      (None, 10)                      650          #> ================================================================================ #> Total params: 50,890 #> Trainable params: 50,890 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 20 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.6191 - accuracy: 0.0000e+00 - val_loss: 2.5341 - val_accuracy: 0.2500 - 1s/epoch - 1s/step #> Epoch 2/2 #> 1/1 - 0s - loss: 2.1479 - accuracy: 0.3125 - val_loss: 2.4921 - val_accuracy: 0.2500 - 43ms/epoch - 43ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 2.518125  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.1  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > guild_view() run <- ls_runs() str(run) #> tibble [1 × 17] (S3: tbl_df/tbl/data.frame) #>  $ shortId   : chr \"b2c52e5a\" #>  $ label     : chr \".fast=yes batch_size=32.0 epochs=20.0 learning_rate=0.001 units=64.0\" #>  $ flags     : tibble [1 × 5] (S3: tbl_df/tbl/data.frame) #>   ..$ .fast        : logi TRUE #>   ..$ batch_size   : num 32 #>   ..$ epochs       : num 20 #>   ..$ learning_rate: num 0.001 #>   ..$ units        : num 64 #>  $ scalars   :List of 1 #>   ..$ : tibble [2 × 14] (S3: tbl_df/tbl/data.frame) #>   .. ..$ run       : chr [1:2] \"b2c52e5abf5448ea91a6282444162099\" \"b2c52e5abf5448ea91a6282444162099\" #>   .. ..$ prefix    : chr [1:2] \".guild\" \".guild\" #>   .. ..$ tag       : chr [1:2] \"test_accuracy\" \"test_loss\" #>   .. ..$ first_val : num [1:2] 0.1 2.52 #>   .. ..$ first_step: int [1:2] 0 0 #>   .. ..$ last_val  : num [1:2] 0.1 2.52 #>   .. ..$ last_step : int [1:2] 0 0 #>   .. ..$ min_val   : num [1:2] 0.1 2.52 #>   .. ..$ min_step  : int [1:2] 0 0 #>   .. ..$ max_val   : num [1:2] 0.1 2.52 #>   .. ..$ max_step  : int [1:2] 0 0 #>   .. ..$ avg_val   : num [1:2] 0.1 2.52 #>   .. ..$ total     : num [1:2] 0.1 2.52 #>   .. ..$ count     : int [1:2] 1 1 #>  $ dir       : chr \"/home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/b2c52e5abf5448ea91a6282444162099\" #>  $ operation : chr \"fashion-mnist.R\" #>  $ started   : POSIXct[1:1], format: \"2022-10-21 11:10:12\" #>  $ stopped   : POSIXct[1:1], format: \"2022-10-21 11:10:21\" #>  $ time      : chr \"0:00:08\" #>  $ tags      : chr \"\" #>  $ comments  :List of 1 #>   ..$ : chr(0)  #>  $ status    : chr \"completed\" #>  $ exitStatus: int 0 #>  $ otherAttrs:'data.frame':  1 obs. of  0 variables #>  $ deps      :List of 1 #>   ..$ : list() #>  $ projectDir: chr \"/home/tomasz/guild/guildai-r/vignettes/articles\" #>  $ id        : chr \"b2c52e5abf5448ea91a6282444162099\" fs::dir_tree(run$dir, all=TRUE) #> /home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/b2c52e5abf5448ea91a6282444162099 #> ├── .guild #> │   ├── attrs #> │   │   ├── cmd #> │   │   ├── deps #> │   │   ├── env #> │   │   ├── exit_status #> │   │   ├── flags #> │   │   ├── host #> │   │   ├── id #> │   │   ├── initialized #> │   │   ├── label #> │   │   ├── op #> │   │   ├── platform #> │   │   ├── random_seed #> │   │   ├── run_params #> │   │   ├── sourcecode_digest #> │   │   ├── started #> │   │   ├── stopped #> │   │   ├── user #> │   │   ├── user_flags #> │   │   └── vcs_commit #> │   ├── events.out.tfevents.1666365020.horse.10305.0 #> │   ├── manifest #> │   ├── opref #> │   ├── output #> │   ├── output.index #> │   └── sourcecode #> │       └── fashion-mnist.R #> └── plots #>     └── Rplot001.png view_run_report(run$id)"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"comparing-runs","dir":"Articles","previous_headings":"","what":"Comparing Runs","title":"Introduction","text":"Let’s make couple changes training script see can improve model performance. ’ll change number units first dense layer 128, change learning_rate 0.001 0.003 run 30 rather 20 epochs. making changes source code re-run script using training_run() : also show us report summarizing results run, really interested comparison run previous one. can view comparison via view_runs_diff() function: comparison report shows model attributes metrics side--side, well differences source code output training script. Note view_runs_diff() default compare last two runs, however can pass two run ids like compared.","code":"#> Replaced expression 'units <- 64' on line 14 with 'units <- 128' #> Replaced expression 'learning_rate <- 0.001' on line 23 with 'learning_rate <- 0.003' #> Replaced expression 'epochs <- 20' on line 36 with 'epochs <- 30' guild_run(\"fashion-mnist.R\") #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:10:24.529679: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2194 - accuracy: 0.1250 - val_loss: 3.0044 - val_accuracy: 0.2500 - 884ms/epoch - 884ms/step #> Epoch 2/2 #> 1/1 - 0s - loss: 1.2208 - accuracy: 0.5000 - val_loss: 3.4903 - val_accuracy: 0.2500 - 37ms/epoch - 37ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 3.320219  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.2  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > view_runs_diff()"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"analyzing-runs","dir":"Articles","previous_headings":"","what":"Analyzing Runs","title":"Introduction","text":"’ve demonstrated visualizing comparing one two runs, however accumulate runs ’ll generally want analyze compare runs many runs. can use ls_runs() function yield data frame summary information runs ’ve conducted.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"flags","dir":"Articles","previous_headings":"","what":"Flags","title":"Introduction","text":"Flags form run inputs, paramaterization. action just , modifying learning_rate, epochs units values script launching second run, can handled us guild_run() using flags interface. default, top-level assignments scalar literals R script identified guild run flags, can modified per-run. can quickly see flags available R script passing --help-op (later). launch run different flag values, can : Now, inspect output view_runs_diff(), see source files associated run updated flag values, modified manually. flags interface useful hyperparamater optimization. ’s simplest, can pass multiple values flag, guild automatically expand combinations grid search. example, launch 4 training runs, combination flag values: precision, can pass dataframe flags values, row corresponding run. Finally, can optionally supply additional metadata individual flags placing hashpipe yaml annotations flag expression. example: Now, descriptions constraints appear --help-op related locations. project grows, ’s helpful able move flag definitions main file. , can include flags-dest frontmatter R script, specifying file path (relative project directory) file guild place flag values. YAML files also supported flags destination: flags flag values associated individual runs returned ls_runs(). Guild runs operations. simple instance, full R script operation. get information specified operation, can add “–help-op” arguments. Note guild automatically recognized Flags operation. Flags allow easily allows running machine learning experiments guild. default, symbols defined top level R scripted scalar literal constants identified flags guild can adjust launching run. example, can ask guild run “fashion-mnist-1.R” larger batch size: Now, ls_runs() returns two-row data frame. can inspect flags, see change:","code":"guild_run(\"fashion-mnist.R\", \"--help-op\") #> Usage: guild run [OPTIONS] fashion-mnist.R [FLAG]... #>  #> Use 'guild run --help' for a list of options. #>  #> Flags: #>   .fast          (default is yes) #>   batch_size     (default is 32.0) #>   epochs         (default is 30.0) #>   learning_rate  (default is 0.003) #>   units          (default is 128.0) guild_run(\"fashion-mnist.R\",            flags = list(learning_rate = c(0.001, 0.003),                        units = c(128, 256))) #> INFO: [guild] Running trial 065cf561a3ab4949bee65dd6f6eec778: fashion-mnist.R (.fast=yes, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=128.0) #> Replaced expression 'learning_rate <- 0.003' on line 23 with 'learning_rate <- 0.001' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:10:41.744141: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2507 - accuracy: 0.0000e+00 - val_loss: 2.5298 - val_accuracy: 0.2500 - 1s/epoch - 1s/step #> Epoch 2/2 #> 1/1 - 0s - loss: 1.6769 - accuracy: 0.4375 - val_loss: 2.8370 - val_accuracy: 0.2500 - 60ms/epoch - 60ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 2.980134  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.15  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial d0ab1c3bdd7043d5960ae2d487dfb006: fashion-mnist.R (.fast=yes, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=256.0) #> Replaced expression 'units <- 128' on line 14 with 'units <- 256' #> Replaced expression 'learning_rate <- 0.003' on line 23 with 'learning_rate <- 0.001' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:10:48.823593: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 256 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.001 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 256)                     200960       #>  dense (Dense)                      (None, 10)                      2570         #> ================================================================================ #> Total params: 203,530 #> Trainable params: 203,530 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2208 - accuracy: 0.1250 - val_loss: 2.6775 - val_accuracy: 0.2500 - 1s/epoch - 1s/step #> Epoch 2/2 #> 1/1 - 0s - loss: 1.4627 - accuracy: 0.5625 - val_loss: 2.9635 - val_accuracy: 0.2500 - 39ms/epoch - 39ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 2.818139  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.25  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial 78e198214a334eae9ad70d9746c0405e: fashion-mnist.R (.fast=yes, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=128.0) #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:10:57.182763: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2651 - accuracy: 0.1875 - val_loss: 3.2124 - val_accuracy: 0.2500 - 891ms/epoch - 891ms/step #> Epoch 2/2 #> 1/1 - 0s - loss: 1.3404 - accuracy: 0.5625 - val_loss: 3.8982 - val_accuracy: 0.2500 - 42ms/epoch - 42ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 3.370405  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.2  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> >  #> INFO: [guild] Running trial 9fb445b5377648cea7fc1896deb30c9f: fashion-mnist.R (.fast=yes, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=256.0) #> Replaced expression 'units <- 128' on line 14 with 'units <- 256' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:11:03.943330: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 256 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 256)                     200960       #>  dense (Dense)                      (None, 10)                      2570         #> ================================================================================ #> Total params: 203,530 #> Trainable params: 203,530 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 32 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2203 - accuracy: 0.1875 - val_loss: 3.4661 - val_accuracy: 0.2500 - 1s/epoch - 1s/step #> Epoch 2/2 #> 1/1 - 0s - loss: 0.9872 - accuracy: 0.6875 - val_loss: 4.8555 - val_accuracy: 0.2500 - 36ms/epoch - 36ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 4.082088  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.25  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > flags_df <- expand.grid(learning_rate = c(0.001, 0.003),                         units = c(128, 256)) flags_df #>   learning_rate units #> 1         0.001   128 #> 2         0.003   128 #> 3         0.001   256 #> 4         0.003   256 guild_run(\"fashion-mnist.R\", flags = flags_df) #| description: size of first layer. #| min: 16 #| max: 256 units <- 32  #| description: Activation function to use. #| choices: [relu, sigmoid, tanh] activation <- \"relu\" #| flags-dest: ./flags.R  FLAGS <- envir::include(\"flags.R\", new.env()) #| flags-dest: ./flags.yml  FLAGS <- yaml::read_yaml(\"flags.yml\") guild_run(\"fashion-mnist.R\", \"--help-op\") #> Usage: guild run [OPTIONS] fashion-mnist.R [FLAG]... #>  #> Use 'guild run --help' for a list of options. #>  #> Flags: #>   .fast          (default is yes) #>   batch_size     (default is 32.0) #>   epochs         (default is 30.0) #>   learning_rate  (default is 0.003) #>   units          (default is 128.0) guild_run(\"fashion-mnist.R\", flags = c(batch_size = 16)) #> Warning in flags$.fast <- TRUE: Coercing LHS to a list #> Replaced expression 'batch_size <- 32' on line 35 with 'batch_size <- 16' #> > library(keras) #> > # Prepare data ---- #> > fashion_mnist <- dataset_fashion_mnist() #> 2022-10-21 11:11:13.647976: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered #> > c(train_images, train_labels) %<-% fashion_mnist$train #> > c(test_images, test_labels) %<-% fashion_mnist$test #> > train_images <- train_images / 255 #> >  test_images <- test_images / 255 #> > # Define model ---- #> >  #> > units <- 128 #> > model <- keras_model_sequential(input_shape = c(28, 28)) #> > model %>% #> +   layer_flatten() %>% #> +   layer_dense(units = units, activation = 'relu') %>% #> +   layer_dense(units = 10, activation = 'softmax') #> > learning_rate <- 0.003 #> > model %>% compile( #> +   optimizer = optimizer_adam(learning_rate), #> +   loss = 'sparse_categorical_crossentropy', #> +   metrics = c('accuracy') #> + ) #> > model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  flatten (Flatten)                  (None, 784)                     0            #>  dense_1 (Dense)                    (None, 128)                     100480       #>  dense (Dense)                      (None, 10)                      1290         #> ================================================================================ #> Total params: 101,770 #> Trainable params: 101,770 #> Non-trainable params: 0 #> ________________________________________________________________________________ #> > # Fit model ---- #> >  #> > batch_size <- 16 #> > epochs <- 30 #> > .fast <- TRUE #> > if (.fast) { #> +   n <- 1:20 #> +   train_images %<>% { .[n, ,] } #> +   test_images %<>% { .[n, ,] } #> +   test_labels %<>% { .[n] } #> +   train_labels %<>% { .[n] } #> +   epochs <- 2 #> + } #> > history <- model %>% #> +   fit(train_images, train_labels, #> +       validation_split = 0.2, #> +       batch_size = batch_size, #> +       epochs = epochs, #> +       verbose = 2) #> Epoch 1/2 #> 1/1 - 1s - loss: 2.2026 - accuracy: 0.1250 - val_loss: 3.0088 - val_accuracy: 0.2500 - 879ms/epoch - 879ms/step #> Epoch 2/2 #> 1/1 - 0s - loss: 1.1780 - accuracy: 0.7500 - val_loss: 3.7330 - val_accuracy: 0.2500 - 35ms/epoch - 35ms/step #> > plot(history) #> > # Evaluate model ---- #> >  #> > score <- model %>% #> +   evaluate(test_images, test_labels, #> +            verbose = 0) %>% #> +   as.list() #> > cat('test_loss:', score$loss, \"\\n\") #> test_loss: 3.290912  #> > cat('test_accuracy:', score$accuracy, \"\\n\") #> test_accuracy: 0.25  #> > # save_model_tf(model, \"model.keras\") #> > # saveRDS(history, \"history.rds\") #> >  #> > runs <- ls_runs() runs %>%   select(shortId, flags) #%>% tidyr::unnest(flags, names_sep = \"_\") #> # A tibble: 8 × 2 #>   shortId  flags$.fast $batch_size $epochs $learning_rate $units #>   <chr>    <lgl>             <dbl>   <dbl>          <dbl>  <dbl> #> 1 c4722120 TRUE                 16      30          0.003    128 #> 2 9fb445b5 TRUE                 32      30          0.003    256 #> 3 78e19821 TRUE                 32      30          0.003    128 #> 4 d0ab1c3b TRUE                 32      30          0.001    256 #> 5 065cf561 TRUE                 32      30          0.001    128 #> 6 8d0634a7 TRUE                 32      30          0.001    256 #> 7 aaad2915 TRUE                 32      30          0.003    128 #> 8 b2c52e5a TRUE                 32      20          0.001     64"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"scalars","dir":"Articles","previous_headings":"","what":"Scalars","title":"Introduction","text":"counterpart run flags run scalars. flags type run input, scalars run outputs identified guild meaningful track. see guild automatically identified test_accuracy test_loss run scalar outputs. default, lines printed standard output run form \"key: value\" recorded guild scalars. scalar key output multiple times run (e.g, loss training loop), sure also print step scalar, enable guild track history (enable visualization run tensorboard). Alternatively, run process produces tensorboard logs directly (e.g., keras::callback_tensorboard()), logs also identified run scalars. ls_runs() default returns summary run scalars, full scalar history can also accessed R directly:","code":"runs %>%   select(shortId, scalars) #> # A tibble: 8 × 2 #>   shortId  scalars           #>   <chr>    <list>            #> 1 c4722120 <tibble [2 × 14]> #> 2 9fb445b5 <tibble [2 × 14]> #> 3 78e19821 <tibble [2 × 14]> #> 4 d0ab1c3b <tibble [2 × 14]> #> 5 065cf561 <tibble [2 × 14]> #> 6 8d0634a7 <tibble [2 × 14]> #> 7 aaad2915 <tibble [2 × 14]> #> 8 b2c52e5a <tibble [2 × 14]>  glimpse(runs$scalars[[1]]) #> Rows: 2 #> Columns: 14 #> $ run        <chr> \"c4722120033f4c30a12e53e261dbbeeb\", \"c4722120033f4c30a12e53… #> $ prefix     <chr> \".guild\", \".guild\" #> $ tag        <chr> \"test_accuracy\", \"test_loss\" #> $ first_val  <dbl> 0.250000, 3.290912 #> $ first_step <int> 0, 0 #> $ last_val   <dbl> 0.250000, 3.290912 #> $ last_step  <int> 0, 0 #> $ min_val    <dbl> 0.250000, 3.290912 #> $ min_step   <int> 0, 0 #> $ max_val    <dbl> 0.250000, 3.290912 #> $ max_step   <int> 0, 0 #> $ avg_val    <dbl> 0.250000, 3.290912 #> $ total      <dbl> 0.250000, 3.290912 #> $ count      <int> 1, 1 ls_runs(scalars = TRUE) #> # A tibble: 16 × 5 #>    run                              path   tag           value  step #>    <chr>                            <chr>  <chr>         <dbl> <int> #>  1 c4722120033f4c30a12e53e261dbbeeb .guild test_loss     3.29      0 #>  2 c4722120033f4c30a12e53e261dbbeeb .guild test_accuracy 0.25      0 #>  3 9fb445b5377648cea7fc1896deb30c9f .guild test_loss     4.08      0 #>  4 9fb445b5377648cea7fc1896deb30c9f .guild test_accuracy 0.25      0 #>  5 78e198214a334eae9ad70d9746c0405e .guild test_loss     3.37      0 #>  6 78e198214a334eae9ad70d9746c0405e .guild test_accuracy 0.200     0 #>  7 d0ab1c3bdd7043d5960ae2d487dfb006 .guild test_loss     2.82      0 #>  8 d0ab1c3bdd7043d5960ae2d487dfb006 .guild test_accuracy 0.25      0 #>  9 065cf561a3ab4949bee65dd6f6eec778 .guild test_loss     2.98      0 #> 10 065cf561a3ab4949bee65dd6f6eec778 .guild test_accuracy 0.150     0 #> 11 8d0634a722fd41e58456d18147eb2c6b .guild test_loss     2.62      0 #> 12 8d0634a722fd41e58456d18147eb2c6b .guild test_accuracy 0.200     0 #> 13 aaad29158729450b82b0576c0ca38458 .guild test_loss     3.32      0 #> 14 aaad29158729450b82b0576c0ca38458 .guild test_accuracy 0.200     0 #> 15 b2c52e5abf5448ea91a6282444162099 .guild test_loss     2.52      0 #> 16 b2c52e5abf5448ea91a6282444162099 .guild test_accuracy 0.100     0"},{"path":"https://t-kalinowski.github.io/guildai-r/articles/intro.html","id":"hyperparamater-tuning","dir":"Articles","previous_headings":"Scalars","what":"Hyperparamater Tuning","title":"Introduction","text":"can investigate impact flag values test_accuracy.","code":"runs <- ls_runs()  df <- runs %>%   select(flags, scalars) %>%   mutate(scalars = lapply(     scalars,     function(sc_df) sc_df %>%       select(tag, last_val) %>%       tidyr::pivot_wider(names_from = tag,                          values_from = last_val)   )) %>%   tidyr::unnest(c(flags, scalars)) %>%   arrange(units)  df #> # A tibble: 8 × 7 #>   .fast batch_size epochs learning_rate units test_accuracy test_loss #>   <lgl>      <dbl>  <dbl>         <dbl> <dbl>         <dbl>     <dbl> #> 1 TRUE          32     20         0.001    64         0.100      2.52 #> 2 TRUE          16     30         0.003   128         0.25       3.29 #> 3 TRUE          32     30         0.003   128         0.200      3.37 #> 4 TRUE          32     30         0.001   128         0.150      2.98 #> 5 TRUE          32     30         0.003   128         0.200      3.32 #> 6 TRUE          32     30         0.003   256         0.25       4.08 #> 7 TRUE          32     30         0.001   256         0.25       2.82 #> 8 TRUE          32     30         0.001   256         0.200      2.62 library(ggplot2) ggplot(df, aes(x = units, y = test_accuracy,                 color = factor(learning_rate))) +   geom_point() + geom_smooth() #> `geom_smooth()` using method = 'loess' and formula 'y ~ x' #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : span too small. fewer data values than degrees of freedom. #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : pseudoinverse used at 63.04 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : neighborhood radius 192.96 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : reciprocal condition number 0 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : There are other near singularities as well. 16631 #> Warning in predLoess(object$y, object$x, newx = if #> (is.null(newdata)) object$x else if (is.data.frame(newdata)) #> as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer #> data values than degrees of freedom. #> Warning in predLoess(object$y, object$x, newx = if #> (is.null(newdata)) object$x else if (is.data.frame(newdata)) #> as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at #> 63.04 #> Warning in predLoess(object$y, object$x, newx = if #> (is.null(newdata)) object$x else if (is.data.frame(newdata)) #> as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius #> 192.96 #> Warning in predLoess(object$y, object$x, newx = if #> (is.null(newdata)) object$x else if (is.data.frame(newdata)) #> as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition #> number 0 #> Warning in predLoess(object$y, object$x, newx = if #> (is.null(newdata)) object$x else if (is.data.frame(newdata)) #> as.matrix(model.frame(delete.response(terms(object)), : There are other near #> singularities as well. 16631 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : span too small. fewer data values than degrees of freedom. #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : at 127.36 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : radius 0.4096 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : all data on boundary of neighborhood. make span bigger #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : pseudoinverse used at 127.36 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : neighborhood radius 0.64 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : reciprocal condition number 1 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : There are other near singularities as well. 16548 #> Warning in simpleLoess(y, x, w, span, degree = degree, parametric = #> parametric, : zero-width neighborhood. make span bigger #> Warning: Computation failed in `stat_smooth()`: #> NA/NaN/Inf in foreign function call (arg 5) # df %>% #   # arrange(batch_size) %>% #   plot(test_accuracy ~ units, data = ., type = 'p') knitr::knit_exit()"},{"path":"https://t-kalinowski.github.io/guildai-r/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tomasz Kalinowski. Author, copyright holder, maintainer.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalinowski T (2022). guildai: R interface guildai. R package version 0.0.0.9001, https://t-kalinowski.github.io/guildai-r/.","code":"@Manual{,   title = {guildai: R interface to guildai},   author = {Tomasz Kalinowski},   year = {2022},   note = {R package version 0.0.0.9001},   url = {https://t-kalinowski.github.io/guildai-r/}, }"},{"path":"https://t-kalinowski.github.io/guildai-r/index.html","id":"guildai","dir":"","previous_headings":"","what":"R interface to guildai","title":"R interface to guildai","text":"goal guildai …","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R interface to guildai","text":"can install development version guildai GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"t-kalinowski/guildai-r\") Rscript -e 'remotes::install_github(\"t-kalinowski/guildai-r\")'"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch a guild run — guild_run","title":"Launch a guild run — guild_run","text":"Launch guild run","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch a guild run — guild_run","text":"","code":"guild_run(   opspec = \"train.R\",   flags = NULL,   ...,   wait = TRUE,   label = NULL,   tags = NULL,   echo = wait )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch a guild run — guild_run","text":"opspec typically path R script, scalar string guild recognizes valid opspec. flags - named list vector like `c(noise = .3, dropout = .4)` - scalar string like `\"noise=.3 dropout=.4\"` - dataframe flags batch runs ... Arguments passed base::system2 command system command invoked, character string. args character vector arguments command. stdout,stderr output stdout     stderr sent.  Possible values \"\", R     console (default), NULL FALSE (discard output),     TRUE (capture output character vector)     character string naming file. stdin input diverted?  \"\" means default,     alternatively character string naming file.  Ignored     input supplied. input character vector supplied, copied one     string per line temporary file, standard input     command redirected file. env character vector name=value strings set environment     variables. timeout timeout seconds, ignored 0.  limit     elapsed time running command separate process.   Fractions     seconds ignored. minimized,invisible arguments accepted Windows     ignored platform, warning. wait whether wait run finish label, tags optional strings used label tag experiments. echo whether output run shown current R console. Note, effect whether expressions echoed guild run stdout.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch a guild run — guild_run","text":"return value `system2()`, invisibly. function   primarily called side effect.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch Guild Viewer — guild_view","title":"Launch Guild Viewer — guild_view","text":"Launch Guild Viewer","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch Guild Viewer — guild_view","text":"","code":"guild_view(..., wait = FALSE)"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/guild_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch Guild Viewer — guild_view","text":"... passed `guild` binary wait whether block R console application active.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":null,"dir":"Reference","previous_headings":"","what":"Install guildai core — install_guild","title":"Install guildai core — install_guild","text":"Install guildai core","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install guildai core — install_guild","text":"","code":"install_guild(guildai = \"guildai\", python = find_python())"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install guildai core — install_guild","text":"guildai character vector passed directly `pip install`. python path python binary, used create private venv.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install guildai core — install_guild","text":"path guild binary","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/install_guild.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install guildai core — install_guild","text":"","code":"# install_guild(c(\"-e\", \"~/guild/guildai\")) # install_guild(\"~/guildai\", reticulate::install_python()) # install_guild(\"https://api.github.com/repos/guildai/guildai/tarball/HEAD\") # install_guild( #   guildai = \"https://api.github.com/repos/guildai/guildai/tarball/HEAD\", #   python = reticulate::install_python()) #"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":null,"dir":"Reference","previous_headings":"","what":"Is code executing in the context of a guild run? — is_run_active","title":"Is code executing in the context of a guild run? — is_run_active","text":"code executing context guild run?","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is code executing in the context of a guild run? — is_run_active","text":"","code":"is_run_active()"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/is_run_active.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is code executing in the context of a guild run? — is_run_active","text":"Boolean","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":null,"dir":"Reference","previous_headings":"","what":"list guild runs — ls_runs","title":"list guild runs — ls_runs","text":"list guild runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list guild runs — ls_runs","text":"","code":"ls_runs(..., full = FALSE, scalars = FALSE)"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"list guild runs — ls_runs","text":"... additional arguments passed `guild api runs`. Try `\"--help\"` see options. full Whether include available run info. scalars Wheter export scalars requested runs instead.","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/ls_runs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"list guild runs — ls_runs","text":"dataframe runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Render a Run Summary Report — view_run_report","title":"Render a Run Summary Report — view_run_report","text":"Render Run Summary Report","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render a Run Summary Report — view_run_report","text":"","code":"view_run_report(   id = ls_runs(\"1\")$id,   output_dir = file.path(tempdir(), id),   template = system.file(\"templates/view-run.qmd\", package = \"guildai\"),   viewer = getOption(\"guildai.viewer\"),   ... )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render a Run Summary Report — view_run_report","text":"id run id. Defaults latest run. output_dir directory place rendered document. template path parameterized quarto document. viewer Viewer display training run information within (default internal page viewer available, otherwise R session default web browser, `utils::browseURL()`). ... passed `quarto::quarto_render()`","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_run_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Render a Run Summary Report — view_run_report","text":"path generated html, invisibly","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"compare runs — view_runs_diff","title":"compare runs — view_runs_diff","text":"compare runs","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compare runs — view_runs_diff","text":"","code":"view_runs_diff(   ids = ls_runs(\"1:2\")$id,   output_dir = file.path(tempdir(), paste(ids, collapse = \"-\")),   template = system.file(\"templates/compare-runs.qmd\", package = \"guildai\"),   viewer = getOption(\"guildai.viewer\"),   ... )"},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compare runs — view_runs_diff","text":"ids, length 2 character vector run ids output_dir place rendered html template report template viewer Viewer display training run information within (default internal page viewer available, otherwise R session default web browser, `utils::browseURL()`). ... passed `quarto::quarto_render()`","code":""},{"path":"https://t-kalinowski.github.io/guildai-r/reference/view_runs_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"compare runs — view_runs_diff","text":"path generated html, invisibly","code":""}]

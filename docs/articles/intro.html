<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="guildai">
<title>Introduction • guildai</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
<meta property="og:description" content="guildai">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">guildai</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9001</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/intro.html">Introduction</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Introduction</h1>
            
      
      
      <div class="d-none name"><code>intro.Rmd</code></div>
    </div>

    
    
<!-- a nice screenshot image here-->
<p><em>guildai</em> provides a suite of tools for tracking, visualizing,
and managing training runs and experiments. The {guildai} R package is a
successor to the {tfruns} package.</p>
<ul>
<li><p>Track the hyperparameters, metrics, output, and source code of
every training run.</p></li>
<li><p>Compare hyperparmaeters and metrics across runs to find the best
performing model.</p></li>
<li><p>Automatically generate reports to visualize individual training
runs or comparisons between runs.</p></li>
<li><p>No changes to source code required.</p></li>
</ul>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>The R package provides an interface to <a href="https://guild.ai/" class="external-link">guildai core</a>. The R package will install
guildai core on first use, or you can call <code><a href="../reference/install_guild.html">install_guild()</a></code>
to customize the installation. You can install the
<strong>guildai</strong> package from CRAN as follows:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"guildai"</span><span class="op">)</span></span>
<span><span class="fu">guildai</span><span class="fu">::</span><span class="fu"><a href="../reference/install_guild.html">install_guild</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>{guildai} can be used with any machine learning framework, or even no
framework at all. For this introductory example, we’ll start with a
Keras model applied to the fashion mnist dataset.</p>
<p>If you’ve not used Keras from R before and you want to follow along
on your machine, you can install it like this:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"keras"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.rstudio.com" class="external-link">keras</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/install_keras.html" class="external-link">install_keras</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="hello-world">Hello World<a class="anchor" aria-label="anchor" href="#hello-world"></a>
</h2>
<p>To start, we’ll setup a sample project folder with one script.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/files.html" class="external-link">file.copy</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"examples/fashion-mnist.R"</span>, package <span class="op">=</span> <span class="st">"guildai"</span><span class="op">)</span>,</span>
<span>          <span class="st">"."</span>, overwrite <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>Here is what the training script looks like:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.rstudio.com" class="external-link">keras</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare data ----</span></span>
<span><span class="va">fashion_mnist</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/dataset_fashion_mnist.html" class="external-link">dataset_fashion_mnist</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_images</span>, <span class="va">train_labels</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="va">fashion_mnist</span><span class="op">$</span><span class="va">train</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">test_images</span>, <span class="va">test_labels</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="va">fashion_mnist</span><span class="op">$</span><span class="va">test</span></span>
<span></span>
<span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="va">train_images</span> <span class="op">/</span> <span class="fl">255</span></span>
<span> <span class="va">test_images</span> <span class="op">&lt;-</span> <span class="va">test_images</span> <span class="op">/</span> <span class="fl">255</span></span>
<span></span>
<span><span class="co"># Define model ----</span></span>
<span></span>
<span><span class="va">units</span> <span class="op">&lt;-</span> <span class="fl">64</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html" class="external-link">keras_model_sequential</a></span><span class="op">(</span>input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">28</span>, <span class="fl">28</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_flatten.html" class="external-link">layer_flatten</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">units</span>, activation <span class="op">=</span> <span class="st">'relu'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span>, activation <span class="op">=</span> <span class="st">'softmax'</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">learning_rate</span> <span class="op">&lt;-</span> <span class="fl">0.001</span></span>
<span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span><span class="va">learning_rate</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'accuracy'</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span></span>
<span></span>
<span><span class="co"># Fit model ----</span></span>
<span></span>
<span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span><span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span></span>
<span><span class="va">.fast</span> <span class="op">&lt;-</span> <span class="cn">TRUE</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="va">.fast</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span></span>
<span>  <span class="va">train_images</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="op">{</span> <span class="va">.</span><span class="op">[</span><span class="va">n</span>, ,<span class="op">]</span> <span class="op">}</span></span>
<span>  <span class="va">test_images</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="op">{</span> <span class="va">.</span><span class="op">[</span><span class="va">n</span>, ,<span class="op">]</span> <span class="op">}</span></span>
<span>  <span class="va">test_labels</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="op">{</span> <span class="va">.</span><span class="op">[</span><span class="va">n</span><span class="op">]</span> <span class="op">}</span></span>
<span>  <span class="va">train_labels</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="op">{</span> <span class="va">.</span><span class="op">[</span><span class="va">n</span><span class="op">]</span> <span class="op">}</span></span>
<span>  <span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_images</span>, <span class="va">train_labels</span>,</span>
<span>      validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>      batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>      epochs <span class="op">=</span> <span class="va">epochs</span>,</span>
<span>      verbose <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate model ----</span></span>
<span></span>
<span><span class="va">score</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">test_images</span>, <span class="va">test_labels</span>,</span>
<span>           verbose <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">as.list</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">'test_loss:'</span>, <span class="va">score</span><span class="op">$</span><span class="va">loss</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">'test_accuracy:'</span>, <span class="va">score</span><span class="op">$</span><span class="va">accuracy</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># save_model_tf(model, "model.keras")</span></span>
<span><span class="co"># saveRDS(history, "history.rds")</span></span></code></pre></div>
<p>To train a model with <strong>guildai</strong>, just use the
<code><a href="../reference/guild_run.html">guild_run()</a></code> function in place of the <code><a href="https://rdrr.io/r/base/source.html" class="external-link">source()</a></code>
function to execute your R script. For example:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:29:42.766877: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 64</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.001</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 64)                      50240       </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      650         </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 50,890</span></span>
<span><span class="co">#&gt; Trainable params: 50,890</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 20</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 4s - loss: 0.5456 - accuracy: 0.8106 - val_loss: 0.4383 - val_accuracy: 0.8480 - 4s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.4089 - accuracy: 0.8545 - val_loss: 0.4082 - val_accuracy: 0.8521 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.3707 - accuracy: 0.8678 - val_loss: 0.3700 - val_accuracy: 0.8667 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.3474 - accuracy: 0.8732 - val_loss: 0.3619 - val_accuracy: 0.8707 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.3267 - accuracy: 0.8802 - val_loss: 0.3920 - val_accuracy: 0.8585 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.3132 - accuracy: 0.8865 - val_loss: 0.3505 - val_accuracy: 0.8763 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.2995 - accuracy: 0.8901 - val_loss: 0.3623 - val_accuracy: 0.8711 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.2892 - accuracy: 0.8950 - val_loss: 0.3411 - val_accuracy: 0.8799 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2774 - accuracy: 0.8970 - val_loss: 0.3286 - val_accuracy: 0.8837 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2701 - accuracy: 0.9006 - val_loss: 0.3225 - val_accuracy: 0.8866 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.2606 - accuracy: 0.9033 - val_loss: 0.3427 - val_accuracy: 0.8799 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2532 - accuracy: 0.9070 - val_loss: 0.3423 - val_accuracy: 0.8834 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2468 - accuracy: 0.9086 - val_loss: 0.3337 - val_accuracy: 0.8859 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2414 - accuracy: 0.9100 - val_loss: 0.3748 - val_accuracy: 0.8712 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2353 - accuracy: 0.9138 - val_loss: 0.3375 - val_accuracy: 0.8839 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2309 - accuracy: 0.9147 - val_loss: 0.3452 - val_accuracy: 0.8855 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2230 - accuracy: 0.9170 - val_loss: 0.3336 - val_accuracy: 0.8881 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2184 - accuracy: 0.9194 - val_loss: 0.3408 - val_accuracy: 0.8850 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2143 - accuracy: 0.9202 - val_loss: 0.3514 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/20</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2113 - accuracy: 0.9211 - val_loss: 0.3433 - val_accuracy: 0.8845 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.3687011 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.882 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt;</span></span></code></pre></div>
<p>By default, the output stream of the run will be shown at the R
console. After launching a run, you can launch an application to view
your runs with <code><a href="../reference/guild_view.html">guild_view()</a></code>. From the Guild View
application, you can also visualize run results using tensorboard.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_view.html">guild_view</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<!-- Include a screenshot here -->
<p>You can also retrieve a data frame with information about the run
with <code><a href="../reference/ls_runs.html">ls_runs()</a></code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">run</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ls_runs.html">ls_runs</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">run</span><span class="op">)</span></span>
<span><span class="co">#&gt; tibble [1 × 17] (S3: tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;  $ shortId   : chr "f4375fbc"</span></span>
<span><span class="co">#&gt;  $ label     : chr ".fast=no batch_size=32.0 epochs=20.0 learning_rate=0.001 units=64.0"</span></span>
<span><span class="co">#&gt;  $ flags     : tibble [1 × 5] (S3: tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;   ..$ .fast        : logi FALSE</span></span>
<span><span class="co">#&gt;   ..$ batch_size   : num 32</span></span>
<span><span class="co">#&gt;   ..$ epochs       : num 20</span></span>
<span><span class="co">#&gt;   ..$ learning_rate: num 0.001</span></span>
<span><span class="co">#&gt;   ..$ units        : num 64</span></span>
<span><span class="co">#&gt;  $ scalars   :List of 1</span></span>
<span><span class="co">#&gt;   ..$ : tibble [2 × 14] (S3: tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;   .. ..$ run       : chr [1:2] "f4375fbcfa6b4158b9f8017d87affad7" "f4375fbcfa6b4158b9f8017d87affad7"</span></span>
<span><span class="co">#&gt;   .. ..$ prefix    : chr [1:2] ".guild" ".guild"</span></span>
<span><span class="co">#&gt;   .. ..$ tag       : chr [1:2] "test_accuracy" "test_loss"</span></span>
<span><span class="co">#&gt;   .. ..$ first_val : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ first_step: int [1:2] 0 0</span></span>
<span><span class="co">#&gt;   .. ..$ last_val  : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ last_step : int [1:2] 0 0</span></span>
<span><span class="co">#&gt;   .. ..$ min_val   : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ min_step  : int [1:2] 0 0</span></span>
<span><span class="co">#&gt;   .. ..$ max_val   : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ max_step  : int [1:2] 0 0</span></span>
<span><span class="co">#&gt;   .. ..$ avg_val   : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ total     : num [1:2] 0.882 0.369</span></span>
<span><span class="co">#&gt;   .. ..$ count     : int [1:2] 1 1</span></span>
<span><span class="co">#&gt;  $ dir       : chr "/home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/f4375fbcfa6b4158b9f8017d87affad7"</span></span>
<span><span class="co">#&gt;  $ operation : chr "fashion-mnist.R"</span></span>
<span><span class="co">#&gt;  $ started   : POSIXct[1:1], format: "2022-10-21 13:29:41"</span></span>
<span><span class="co">#&gt;  $ stopped   : POSIXct[1:1], format: "2022-10-21 13:30:39"</span></span>
<span><span class="co">#&gt;  $ time      : chr "0:00:58"</span></span>
<span><span class="co">#&gt;  $ tags      : chr ""</span></span>
<span><span class="co">#&gt;  $ comments  :List of 1</span></span>
<span><span class="co">#&gt;   ..$ : chr(0) </span></span>
<span><span class="co">#&gt;  $ status    : chr "completed"</span></span>
<span><span class="co">#&gt;  $ exitStatus: int 0</span></span>
<span><span class="co">#&gt;  $ otherAttrs:'data.frame':  1 obs. of  0 variables</span></span>
<span><span class="co">#&gt;  $ deps      :List of 1</span></span>
<span><span class="co">#&gt;   ..$ : list()</span></span>
<span><span class="co">#&gt;  $ projectDir: chr "/home/tomasz/guild/guildai-r/vignettes/articles"</span></span>
<span><span class="co">#&gt;  $ id        : chr "f4375fbcfa6b4158b9f8017d87affad7"</span></span></code></pre></div>
<p><code><a href="../reference/ls_runs.html">ls_runs()</a></code> returns a data frame with information about
runs. In our sample project, we’ve launched one run, so
<code><a href="../reference/ls_runs.html">ls_runs()</a></code> returns a 1-row data frame.</p>
<p><code><a href="../reference/guild_view.html">guild_view()</a></code> and <code><a href="../reference/ls_runs.html">ls_runs()</a></code> provide two
convenient ways to gather and present the information from runs.
Importantly however, all the information about the run is stored as
plain files.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">fs</span><span class="fu">::</span><span class="fu"><a href="https://fs.r-lib.org/reference/dir_tree.html" class="external-link">dir_tree</a></span><span class="op">(</span><span class="va">run</span><span class="op">$</span><span class="va">dir</span>, all<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #0000BB; font-weight: bold;">/home/tomasz/guild/guildai-r/vignettes/articles/.guild/runs/f4375fbcfa6b4158b9f8017d87affad7</span></span></span>
<span><span class="co">#&gt; ├── <span style="color: #0000BB; font-weight: bold;">.guild</span></span></span>
<span><span class="co">#&gt; │   ├── <span style="color: #0000BB; font-weight: bold;">attrs</span></span></span>
<span><span class="co">#&gt; │   │   ├── cmd</span></span>
<span><span class="co">#&gt; │   │   ├── deps</span></span>
<span><span class="co">#&gt; │   │   ├── env</span></span>
<span><span class="co">#&gt; │   │   ├── exit_status</span></span>
<span><span class="co">#&gt; │   │   ├── flags</span></span>
<span><span class="co">#&gt; │   │   ├── host</span></span>
<span><span class="co">#&gt; │   │   ├── id</span></span>
<span><span class="co">#&gt; │   │   ├── initialized</span></span>
<span><span class="co">#&gt; │   │   ├── label</span></span>
<span><span class="co">#&gt; │   │   ├── op</span></span>
<span><span class="co">#&gt; │   │   ├── platform</span></span>
<span><span class="co">#&gt; │   │   ├── random_seed</span></span>
<span><span class="co">#&gt; │   │   ├── run_params</span></span>
<span><span class="co">#&gt; │   │   ├── sourcecode_digest</span></span>
<span><span class="co">#&gt; │   │   ├── started</span></span>
<span><span class="co">#&gt; │   │   ├── stopped</span></span>
<span><span class="co">#&gt; │   │   ├── user</span></span>
<span><span class="co">#&gt; │   │   ├── user_flags</span></span>
<span><span class="co">#&gt; │   │   └── vcs_commit</span></span>
<span><span class="co">#&gt; │   ├── events.out.tfevents.1666373439.horse.40983.0</span></span>
<span><span class="co">#&gt; │   ├── manifest</span></span>
<span><span class="co">#&gt; │   ├── opref</span></span>
<span><span class="co">#&gt; │   ├── output</span></span>
<span><span class="co">#&gt; │   ├── output.index</span></span>
<span><span class="co">#&gt; │   └── <span style="color: #0000BB; font-weight: bold;">sourcecode</span></span></span>
<span><span class="co">#&gt; │       └── <span style="color: #00BB00;">fashion-mnist.R</span></span></span>
<span><span class="co">#&gt; └── <span style="color: #0000BB; font-weight: bold;">plots</span></span></span>
<span><span class="co">#&gt;     └── <span style="color: #BB00BB; font-weight: bold;">Rplot001.png</span></span></span></code></pre></div>
<p>A run can also be used to generate a summary report, a paramaterized
quarto document:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/view_run_report.html">view_run_report</a></span><span class="op">(</span><span class="va">run</span><span class="op">$</span><span class="va">id</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="comparing-runs">Comparing Runs<a class="anchor" aria-label="anchor" href="#comparing-runs"></a>
</h3>
<p>Let’s make a couple of changes to our training script to see if we
can improve model performance. We’ll change the number of units in our
first dense layer to 128, change the <code>learning_rate</code> from
0.001 to 0.003 and run 30 rather than 20 <code>epochs</code>. After
making these changes to the source code we re-run the script using
<code><a href="../reference/guild_run.html">guild_run()</a></code> as before:</p>
<pre><code><span><span class="co">#&gt; Replaced expression 'units &lt;- 64' on line 14 with 'units &lt;- 128'</span></span>
<span><span class="co">#&gt; Replaced expression 'learning_rate &lt;- 0.001' on line 23 with 'learning_rate &lt;- 0.003'</span></span>
<span><span class="co">#&gt; Replaced expression 'epochs &lt;- 20' on line 36 with 'epochs &lt;- 30'</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:30:42.601807: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 128</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.003</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 128)                     100480      </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      1290        </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 101,770</span></span>
<span><span class="co">#&gt; Trainable params: 101,770</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 30</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.4960 - accuracy: 0.8217 - val_loss: 0.5522 - val_accuracy: 0.8076 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3872 - accuracy: 0.8581 - val_loss: 0.4036 - val_accuracy: 0.8539 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3562 - accuracy: 0.8684 - val_loss: 0.3957 - val_accuracy: 0.8576 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3318 - accuracy: 0.8772 - val_loss: 0.3620 - val_accuracy: 0.8702 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3131 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.8674 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3023 - accuracy: 0.8873 - val_loss: 0.3929 - val_accuracy: 0.8644 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2913 - accuracy: 0.8909 - val_loss: 0.3719 - val_accuracy: 0.8710 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2811 - accuracy: 0.8940 - val_loss: 0.3495 - val_accuracy: 0.8792 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2743 - accuracy: 0.8971 - val_loss: 0.3405 - val_accuracy: 0.8810 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2665 - accuracy: 0.8996 - val_loss: 0.3728 - val_accuracy: 0.8781 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2566 - accuracy: 0.9025 - val_loss: 0.3438 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2521 - accuracy: 0.9053 - val_loss: 0.3484 - val_accuracy: 0.8816 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2464 - accuracy: 0.9075 - val_loss: 0.3808 - val_accuracy: 0.8798 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2418 - accuracy: 0.9095 - val_loss: 0.3621 - val_accuracy: 0.8792 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2371 - accuracy: 0.9115 - val_loss: 0.3720 - val_accuracy: 0.8802 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2323 - accuracy: 0.9113 - val_loss: 0.4080 - val_accuracy: 0.8724 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2270 - accuracy: 0.9149 - val_loss: 0.3700 - val_accuracy: 0.8837 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2259 - accuracy: 0.9156 - val_loss: 0.3876 - val_accuracy: 0.8762 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2188 - accuracy: 0.9176 - val_loss: 0.3985 - val_accuracy: 0.8790 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2173 - accuracy: 0.9181 - val_loss: 0.3985 - val_accuracy: 0.8786 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 21/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2157 - accuracy: 0.9178 - val_loss: 0.3897 - val_accuracy: 0.8780 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 22/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2097 - accuracy: 0.9204 - val_loss: 0.4196 - val_accuracy: 0.8715 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 23/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2041 - accuracy: 0.9219 - val_loss: 0.4004 - val_accuracy: 0.8847 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 24/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2103 - accuracy: 0.9214 - val_loss: 0.3974 - val_accuracy: 0.8798 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 25/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2015 - accuracy: 0.9237 - val_loss: 0.4226 - val_accuracy: 0.8752 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 26/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1981 - accuracy: 0.9248 - val_loss: 0.4148 - val_accuracy: 0.8790 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 27/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1968 - accuracy: 0.9256 - val_loss: 0.4284 - val_accuracy: 0.8794 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 28/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1941 - accuracy: 0.9254 - val_loss: 0.4420 - val_accuracy: 0.8748 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 29/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1895 - accuracy: 0.9277 - val_loss: 0.4702 - val_accuracy: 0.8709 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 30/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1899 - accuracy: 0.9268 - val_loss: 0.4311 - val_accuracy: 0.8852 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.4695269 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.8785 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt;</span></span></code></pre></div>
<p>This will also show us a report summarizing the results of the run,
but what we are really interested in is a comparison between this run
and the previous one.</p>
<p>The individual metrics <code>test_loss</code> and
<code>test_accuracy</code> are visible in the comparison table in the
Guild View application, as well as in the We can view a comparison via
the <code><a href="../reference/view_runs_diff.html">view_runs_diff()</a></code> function:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/view_runs_diff.html">view_runs_diff</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>The comparison report shows the model attributes and metrics
side-by-side, as well as differences in the source code and output of
the training script.</p>
<p>Note that <code><a href="../reference/view_runs_diff.html">view_runs_diff()</a></code> will by default compare the
last two runs, however you can pass any two run ids you like to be
compared.</p>
</div>
</div>
<div class="section level2">
<h2 id="flags">Flags<a class="anchor" aria-label="anchor" href="#flags"></a>
</h2>
<p>Flags are a form of run inputs, or paramaterization. The action we
just did, of modifying <code>learning_rate</code>, <code>epochs</code>
and <code>units</code> values in the script before launching the second
run, can be handled for us by <code><a href="../reference/guild_run.html">guild_run()</a></code> using the
<em>flags</em> interface.</p>
<p>By default, top-level assignments of scalar literals in an R script
are identified by guild as run flags that can be modified per-run. You
can quickly see what flags are available in an R script by passing
<code>--help-op</code> (more on this later).</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span>, <span class="st">"--help-op"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Usage: guild run [OPTIONS] fashion-mnist.R [FLAG]...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Use 'guild run --help' for a list of options.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Flags:</span></span>
<span><span class="co">#&gt;   .fast          (default is yes)</span></span>
<span><span class="co">#&gt;   batch_size     (default is 32.0)</span></span>
<span><span class="co">#&gt;   epochs         (default is 30.0)</span></span>
<span><span class="co">#&gt;   learning_rate  (default is 0.003)</span></span>
<span><span class="co">#&gt;   units          (default is 128.0)</span></span></code></pre></div>
<p>To launch a run with different flag values, we can do this:</p>
<p>Now, when we inspect the run sources with
<code><a href="../reference/view_runs_diff.html">view_runs_diff()</a></code>, we see that the source files associated
with the run have the updated flag values, as if we had modified them
manually.</p>
<p>The flags interface is useful for hyperparamater optimization. At
it’s simplest, we can just iterate over the set of flag values we
want:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">learning_rate</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.003</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="va">learning_rate</span><span class="op">)</span>,</span>
<span>            wait <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>Here <code>wait = FALSE</code> means that the
<code><a href="../reference/guild_run.html">guild_run()</a></code> call launches the run process and returns
immediately. This is an easy way to launch multiple training runs in
parallel. We can view the progress and real-time outputs of our runs
with <code><a href="../reference/guild_view.html">guild_view()</a></code>, where their status (“training” or
“completed”).</p>
<p>Alternatively, we can pass multiple values for each flag, and guild
will automatically expand the combinations to a grid search. For
example, this will launch 4 training runs, with each combination of flag
values:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span>, </span>
<span>          flags <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.003</span><span class="op">)</span>,</span>
<span>                       units <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">256</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; INFO: [guild] Running trial 44719bd4ec224af1811a0660608b8caa: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=128.0)</span></span>
<span><span class="co">#&gt; Replaced expression 'learning_rate &lt;- 0.003' on line 23 with 'learning_rate &lt;- 0.001'</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:33:24.601613: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 128</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.001</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 128)                     100480      </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      1290        </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 101,770</span></span>
<span><span class="co">#&gt; Trainable params: 101,770</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 30</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.5166 - accuracy: 0.8189 - val_loss: 0.4251 - val_accuracy: 0.8492 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3878 - accuracy: 0.8599 - val_loss: 0.3860 - val_accuracy: 0.8640 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3431 - accuracy: 0.8754 - val_loss: 0.3767 - val_accuracy: 0.8679 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3217 - accuracy: 0.8829 - val_loss: 0.3492 - val_accuracy: 0.8754 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3028 - accuracy: 0.8886 - val_loss: 0.3318 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2873 - accuracy: 0.8946 - val_loss: 0.3329 - val_accuracy: 0.8806 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2731 - accuracy: 0.8985 - val_loss: 0.3232 - val_accuracy: 0.8843 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2618 - accuracy: 0.9036 - val_loss: 0.3225 - val_accuracy: 0.8841 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2507 - accuracy: 0.9074 - val_loss: 0.3467 - val_accuracy: 0.8788 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2416 - accuracy: 0.9096 - val_loss: 0.3379 - val_accuracy: 0.8817 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2348 - accuracy: 0.9115 - val_loss: 0.3361 - val_accuracy: 0.8845 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.3221 - val_accuracy: 0.8889 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2186 - accuracy: 0.9177 - val_loss: 0.3553 - val_accuracy: 0.8773 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2115 - accuracy: 0.9204 - val_loss: 0.3300 - val_accuracy: 0.8880 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2044 - accuracy: 0.9232 - val_loss: 0.3321 - val_accuracy: 0.8887 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2003 - accuracy: 0.9249 - val_loss: 0.3278 - val_accuracy: 0.8903 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1927 - accuracy: 0.9279 - val_loss: 0.3567 - val_accuracy: 0.8838 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1883 - accuracy: 0.9290 - val_loss: 0.3552 - val_accuracy: 0.8858 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1814 - accuracy: 0.9317 - val_loss: 0.3480 - val_accuracy: 0.8877 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1788 - accuracy: 0.9321 - val_loss: 0.3517 - val_accuracy: 0.8882 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 21/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1741 - accuracy: 0.9351 - val_loss: 0.3525 - val_accuracy: 0.8908 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 22/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1678 - accuracy: 0.9375 - val_loss: 0.3745 - val_accuracy: 0.8857 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 23/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1628 - accuracy: 0.9389 - val_loss: 0.3960 - val_accuracy: 0.8838 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 24/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1605 - accuracy: 0.9403 - val_loss: 0.3679 - val_accuracy: 0.8885 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 25/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1572 - accuracy: 0.9417 - val_loss: 0.3830 - val_accuracy: 0.8862 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 26/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1521 - accuracy: 0.9434 - val_loss: 0.3732 - val_accuracy: 0.8918 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 27/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1479 - accuracy: 0.9459 - val_loss: 0.3794 - val_accuracy: 0.8905 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 28/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1461 - accuracy: 0.9452 - val_loss: 0.4029 - val_accuracy: 0.8858 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 29/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1390 - accuracy: 0.9484 - val_loss: 0.3875 - val_accuracy: 0.8902 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 30/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1377 - accuracy: 0.9494 - val_loss: 0.4272 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.4655154 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.8757 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; INFO: [guild] Running trial 7a9d1ce8b5c849b7bfde5fba78308253: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.001, units=256.0)</span></span>
<span><span class="co">#&gt; Replaced expression 'units &lt;- 128' on line 14 with 'units &lt;- 256'</span></span>
<span><span class="co">#&gt; Replaced expression 'learning_rate &lt;- 0.003' on line 23 with 'learning_rate &lt;- 0.001'</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:34:44.388413: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 256</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.001</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 256)                     200960      </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      2570        </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 203,530</span></span>
<span><span class="co">#&gt; Trainable params: 203,530</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 30</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.5037 - accuracy: 0.8212 - val_loss: 0.4364 - val_accuracy: 0.8453 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3778 - accuracy: 0.8640 - val_loss: 0.3844 - val_accuracy: 0.8572 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3363 - accuracy: 0.8761 - val_loss: 0.3637 - val_accuracy: 0.8690 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3100 - accuracy: 0.8846 - val_loss: 0.3379 - val_accuracy: 0.8783 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2895 - accuracy: 0.8925 - val_loss: 0.3268 - val_accuracy: 0.8817 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2754 - accuracy: 0.8974 - val_loss: 0.3107 - val_accuracy: 0.8898 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2631 - accuracy: 0.9017 - val_loss: 0.3072 - val_accuracy: 0.8887 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2496 - accuracy: 0.9054 - val_loss: 0.3356 - val_accuracy: 0.8808 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2377 - accuracy: 0.9116 - val_loss: 0.3033 - val_accuracy: 0.8913 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2291 - accuracy: 0.9147 - val_loss: 0.3249 - val_accuracy: 0.8877 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2213 - accuracy: 0.9180 - val_loss: 0.3128 - val_accuracy: 0.8919 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 4s - loss: 0.2120 - accuracy: 0.9193 - val_loss: 0.3173 - val_accuracy: 0.8898 - 4s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.2055 - accuracy: 0.9225 - val_loss: 0.3260 - val_accuracy: 0.8908 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.1976 - accuracy: 0.9270 - val_loss: 0.3312 - val_accuracy: 0.8820 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1921 - accuracy: 0.9279 - val_loss: 0.3353 - val_accuracy: 0.8920 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1834 - accuracy: 0.9300 - val_loss: 0.3267 - val_accuracy: 0.8913 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1777 - accuracy: 0.9337 - val_loss: 0.3416 - val_accuracy: 0.8928 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1722 - accuracy: 0.9344 - val_loss: 0.3472 - val_accuracy: 0.8862 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1670 - accuracy: 0.9370 - val_loss: 0.3512 - val_accuracy: 0.8918 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1633 - accuracy: 0.9379 - val_loss: 0.3582 - val_accuracy: 0.8891 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 21/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1549 - accuracy: 0.9418 - val_loss: 0.3556 - val_accuracy: 0.8902 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 22/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1532 - accuracy: 0.9429 - val_loss: 0.3514 - val_accuracy: 0.8946 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 23/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1477 - accuracy: 0.9445 - val_loss: 0.3597 - val_accuracy: 0.8936 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 24/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1414 - accuracy: 0.9472 - val_loss: 0.3647 - val_accuracy: 0.8929 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 25/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1394 - accuracy: 0.9473 - val_loss: 0.3681 - val_accuracy: 0.8921 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 26/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1356 - accuracy: 0.9497 - val_loss: 0.4043 - val_accuracy: 0.8823 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 27/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.4060 - val_accuracy: 0.8916 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 28/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1295 - accuracy: 0.9511 - val_loss: 0.3764 - val_accuracy: 0.8955 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 29/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1259 - accuracy: 0.9521 - val_loss: 0.3850 - val_accuracy: 0.8933 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 30/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1234 - accuracy: 0.9532 - val_loss: 0.4001 - val_accuracy: 0.8901 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.4463007 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.8833 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; INFO: [guild] Running trial 157f9b69b3f748ae87300775d7b0d87a: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=128.0)</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:36:02.988859: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 128</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.003</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 128)                     100480      </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      1290        </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 101,770</span></span>
<span><span class="co">#&gt; Trainable params: 101,770</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 30</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.4985 - accuracy: 0.8216 - val_loss: 0.4405 - val_accuracy: 0.8437 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3849 - accuracy: 0.8607 - val_loss: 0.3994 - val_accuracy: 0.8573 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3534 - accuracy: 0.8704 - val_loss: 0.3535 - val_accuracy: 0.8743 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3341 - accuracy: 0.8758 - val_loss: 0.3669 - val_accuracy: 0.8682 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3147 - accuracy: 0.8842 - val_loss: 0.3524 - val_accuracy: 0.8770 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3026 - accuracy: 0.8879 - val_loss: 0.3437 - val_accuracy: 0.8801 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2895 - accuracy: 0.8919 - val_loss: 0.3572 - val_accuracy: 0.8765 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2789 - accuracy: 0.8956 - val_loss: 0.3677 - val_accuracy: 0.8733 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2740 - accuracy: 0.8982 - val_loss: 0.3506 - val_accuracy: 0.8753 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2660 - accuracy: 0.8999 - val_loss: 0.3672 - val_accuracy: 0.8788 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2587 - accuracy: 0.9020 - val_loss: 0.3465 - val_accuracy: 0.8864 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2540 - accuracy: 0.9047 - val_loss: 0.3694 - val_accuracy: 0.8777 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2467 - accuracy: 0.9090 - val_loss: 0.3703 - val_accuracy: 0.8788 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2441 - accuracy: 0.9084 - val_loss: 0.3538 - val_accuracy: 0.8842 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2348 - accuracy: 0.9123 - val_loss: 0.3686 - val_accuracy: 0.8781 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2297 - accuracy: 0.9135 - val_loss: 0.3826 - val_accuracy: 0.8819 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2300 - accuracy: 0.9129 - val_loss: 0.3652 - val_accuracy: 0.8838 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2193 - accuracy: 0.9169 - val_loss: 0.3649 - val_accuracy: 0.8853 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2188 - accuracy: 0.9181 - val_loss: 0.3805 - val_accuracy: 0.8829 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2146 - accuracy: 0.9176 - val_loss: 0.3850 - val_accuracy: 0.8820 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 21/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2102 - accuracy: 0.9208 - val_loss: 0.3870 - val_accuracy: 0.8815 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 22/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2061 - accuracy: 0.9224 - val_loss: 0.3888 - val_accuracy: 0.8796 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 23/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2021 - accuracy: 0.9237 - val_loss: 0.3889 - val_accuracy: 0.8907 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 24/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2000 - accuracy: 0.9240 - val_loss: 0.3891 - val_accuracy: 0.8892 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 25/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1975 - accuracy: 0.9260 - val_loss: 0.4059 - val_accuracy: 0.8868 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 26/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1961 - accuracy: 0.9261 - val_loss: 0.4077 - val_accuracy: 0.8855 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 27/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1926 - accuracy: 0.9265 - val_loss: 0.4143 - val_accuracy: 0.8770 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 28/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1902 - accuracy: 0.9284 - val_loss: 0.4149 - val_accuracy: 0.8893 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 29/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1834 - accuracy: 0.9306 - val_loss: 0.4563 - val_accuracy: 0.8722 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 30/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1837 - accuracy: 0.9311 - val_loss: 0.4241 - val_accuracy: 0.8818 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.4663589 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.8736 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; INFO: [guild] Running trial 4ad73fb75e594fab97369480d01455c1: fashion-mnist.R (.fast=no, batch_size=32.0, epochs=30.0, learning_rate=0.003, units=256.0)</span></span>
<span><span class="co">#&gt; Replaced expression 'units &lt;- 128' on line 14 with 'units &lt;- 256'</span></span>
<span><span class="co">#&gt; Replaced expression '.fast &lt;- TRUE' on line 38 with '.fast &lt;- FALSE'</span></span>
<span><span class="co">#&gt; &gt; library(keras)</span></span>
<span><span class="co">#&gt; &gt; # Prepare data ----</span></span>
<span><span class="co">#&gt; &gt; fashion_mnist &lt;- dataset_fashion_mnist()</span></span>
<span><span class="co">#&gt; 2022-10-21 13:37:15.111377: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered</span></span>
<span><span class="co">#&gt; &gt; c(train_images, train_labels) %&lt;-% fashion_mnist$train</span></span>
<span><span class="co">#&gt; &gt; c(test_images, test_labels) %&lt;-% fashion_mnist$test</span></span>
<span><span class="co">#&gt; &gt; train_images &lt;- train_images / 255</span></span>
<span><span class="co">#&gt; &gt;  test_images &lt;- test_images / 255</span></span>
<span><span class="co">#&gt; &gt; # Define model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; units &lt;- 256</span></span>
<span><span class="co">#&gt; &gt; model &lt;- keras_model_sequential(input_shape = c(28, 28))</span></span>
<span><span class="co">#&gt; &gt; model %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_flatten() %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = units, activation = 'relu') %&gt;%</span></span>
<span><span class="co">#&gt; +   layer_dense(units = 10, activation = 'softmax')</span></span>
<span><span class="co">#&gt; &gt; learning_rate &lt;- 0.003</span></span>
<span><span class="co">#&gt; &gt; model %&gt;% compile(</span></span>
<span><span class="co">#&gt; +   optimizer = optimizer_adam(learning_rate),</span></span>
<span><span class="co">#&gt; +   loss = 'sparse_categorical_crossentropy',</span></span>
<span><span class="co">#&gt; +   metrics = c('accuracy')</span></span>
<span><span class="co">#&gt; + )</span></span>
<span><span class="co">#&gt; &gt; model</span></span>
<span><span class="co">#&gt; Model: "sequential"</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt;  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt;  flatten (Flatten)                  (None, 784)                     0           </span></span>
<span><span class="co">#&gt;  dense_1 (Dense)                    (None, 256)                     200960      </span></span>
<span><span class="co">#&gt;  dense (Dense)                      (None, 10)                      2570        </span></span>
<span><span class="co">#&gt; ================================================================================</span></span>
<span><span class="co">#&gt; Total params: 203,530</span></span>
<span><span class="co">#&gt; Trainable params: 203,530</span></span>
<span><span class="co">#&gt; Non-trainable params: 0</span></span>
<span><span class="co">#&gt; ________________________________________________________________________________</span></span>
<span><span class="co">#&gt; &gt; # Fit model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; batch_size &lt;- 32</span></span>
<span><span class="co">#&gt; &gt; epochs &lt;- 30</span></span>
<span><span class="co">#&gt; &gt; .fast &lt;- FALSE</span></span>
<span><span class="co">#&gt; &gt; if (.fast) {</span></span>
<span><span class="co">#&gt; +   n &lt;- 1:20</span></span>
<span><span class="co">#&gt; +   train_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_images %&lt;&gt;% { .[n, ,] }</span></span>
<span><span class="co">#&gt; +   test_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   train_labels %&lt;&gt;% { .[n] }</span></span>
<span><span class="co">#&gt; +   epochs &lt;- 2</span></span>
<span><span class="co">#&gt; + }</span></span>
<span><span class="co">#&gt; &gt; history &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   fit(train_images, train_labels,</span></span>
<span><span class="co">#&gt; +       validation_split = 0.2,</span></span>
<span><span class="co">#&gt; +       batch_size = batch_size,</span></span>
<span><span class="co">#&gt; +       epochs = epochs,</span></span>
<span><span class="co">#&gt; +       verbose = 2)</span></span>
<span><span class="co">#&gt; Epoch 1/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 3s - loss: 0.5009 - accuracy: 0.8208 - val_loss: 0.4256 - val_accuracy: 0.8424 - 3s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 2/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3857 - accuracy: 0.8580 - val_loss: 0.3752 - val_accuracy: 0.8622 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 3/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3519 - accuracy: 0.8702 - val_loss: 0.3709 - val_accuracy: 0.8632 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 4/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3298 - accuracy: 0.8790 - val_loss: 0.3787 - val_accuracy: 0.8622 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 5/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.3112 - accuracy: 0.8847 - val_loss: 0.3416 - val_accuracy: 0.8794 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 6/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2998 - accuracy: 0.8883 - val_loss: 0.3408 - val_accuracy: 0.8814 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 7/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2861 - accuracy: 0.8923 - val_loss: 0.3429 - val_accuracy: 0.8799 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 8/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2779 - accuracy: 0.8958 - val_loss: 0.3835 - val_accuracy: 0.8713 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 9/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2686 - accuracy: 0.8993 - val_loss: 0.3509 - val_accuracy: 0.8798 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 10/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2652 - accuracy: 0.9009 - val_loss: 0.3598 - val_accuracy: 0.8789 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 11/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2515 - accuracy: 0.9057 - val_loss: 0.3538 - val_accuracy: 0.8773 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 12/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2526 - accuracy: 0.9058 - val_loss: 0.3770 - val_accuracy: 0.8724 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 13/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2442 - accuracy: 0.9087 - val_loss: 0.3619 - val_accuracy: 0.8786 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 14/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2396 - accuracy: 0.9091 - val_loss: 0.3741 - val_accuracy: 0.8780 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 15/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2323 - accuracy: 0.9136 - val_loss: 0.3608 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 16/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2269 - accuracy: 0.9147 - val_loss: 0.3554 - val_accuracy: 0.8869 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 17/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2214 - accuracy: 0.9172 - val_loss: 0.3672 - val_accuracy: 0.8863 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 18/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2212 - accuracy: 0.9162 - val_loss: 0.3642 - val_accuracy: 0.8790 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 19/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2173 - accuracy: 0.9185 - val_loss: 0.4110 - val_accuracy: 0.8793 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 20/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2095 - accuracy: 0.9214 - val_loss: 0.3777 - val_accuracy: 0.8870 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 21/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2110 - accuracy: 0.9210 - val_loss: 0.3732 - val_accuracy: 0.8868 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 22/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2041 - accuracy: 0.9226 - val_loss: 0.3829 - val_accuracy: 0.8865 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 23/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.2014 - accuracy: 0.9241 - val_loss: 0.3810 - val_accuracy: 0.8850 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 24/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1973 - accuracy: 0.9255 - val_loss: 0.4041 - val_accuracy: 0.8841 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 25/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1990 - accuracy: 0.9256 - val_loss: 0.4017 - val_accuracy: 0.8832 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 26/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1904 - accuracy: 0.9276 - val_loss: 0.4150 - val_accuracy: 0.8841 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 27/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1908 - accuracy: 0.9280 - val_loss: 0.4381 - val_accuracy: 0.8812 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; Epoch 28/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1875 - accuracy: 0.9283 - val_loss: 0.4197 - val_accuracy: 0.8892 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 29/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1866 - accuracy: 0.9296 - val_loss: 0.4281 - val_accuracy: 0.8845 - 2s/epoch - 1ms/step</span></span>
<span><span class="co">#&gt; Epoch 30/30</span></span>
<span><span class="co">#&gt; 1500/1500 - 2s - loss: 0.1798 - accuracy: 0.9319 - val_loss: 0.4349 - val_accuracy: 0.8882 - 2s/epoch - 2ms/step</span></span>
<span><span class="co">#&gt; &gt; plot(history)</span></span>
<span><span class="co">#&gt; &gt; # Evaluate model ----</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt; score &lt;- model %&gt;%</span></span>
<span><span class="co">#&gt; +   evaluate(test_images, test_labels,</span></span>
<span><span class="co">#&gt; +            verbose = 0) %&gt;%</span></span>
<span><span class="co">#&gt; +   as.list()</span></span>
<span><span class="co">#&gt; &gt; cat('test_loss:', score$loss, "\n")</span></span>
<span><span class="co">#&gt; test_loss: 0.4721423 </span></span>
<span><span class="co">#&gt; &gt; cat('test_accuracy:', score$accuracy, "\n")</span></span>
<span><span class="co">#&gt; test_accuracy: 0.8751 </span></span>
<span><span class="co">#&gt; &gt; # save_model_tf(model, "model.keras")</span></span>
<span><span class="co">#&gt; &gt; # saveRDS(history, "history.rds")</span></span>
<span><span class="co">#&gt; &gt; </span></span>
<span><span class="co">#&gt; &gt;</span></span></code></pre></div>
<p>For more precision, we can pass a dataframe of flags values, with
each row corresponding to a run.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flags_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.003</span><span class="op">)</span>,</span>
<span>                        units <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">256</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">flags_df</span></span>
<span><span class="co">#&gt;   learning_rate units</span></span>
<span><span class="co">#&gt; 1         0.001   128</span></span>
<span><span class="co">#&gt; 2         0.003   128</span></span>
<span><span class="co">#&gt; 3         0.001   256</span></span>
<span><span class="co">#&gt; 4         0.003   256</span></span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span>, flags <span class="op">=</span> <span class="va">flags_df</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="flag-annotations">Flag annotations<a class="anchor" aria-label="anchor" href="#flag-annotations"></a>
</h3>
<p>We can optionally supply additional metadata about individual flags
by placing hashpipe yaml annotations above the flag expression. For
example, we can update our “fashion-mnist.R” script with the following
lines:</p>
<pre><code><span><span class="co">#| description: size of first layer.</span></span>
<span><span class="co">#| min: 16</span></span>
<span><span class="co">#| max: 256</span></span>
<span><span class="va">units</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span></span>
<span><span class="co">#| description: Activation function to use.</span></span>
<span><span class="co">#| choices: [relu, sigmoid, tanh]</span></span>
<span><span class="va">activation</span> <span class="op">&lt;-</span> <span class="st">"relu"</span></span></code></pre>
<p>Now, the <code>description</code>s and constraints will appear in
<code>--help-op</code> and related locations.</p>
</div>
<div class="section level3">
<h3 id="flag-destinations">Flag destinations<a class="anchor" aria-label="anchor" href="#flag-destinations"></a>
</h3>
<p>As a project grows, it’s helpful to be able to move flag definitions
out of the main R script. To do so, you can include a
<code>flags-dest</code> in the frontmatter of the R script, specifying
the file path (relative to the project directory) of the file where
guild should place the flag values. Then you can read in the flags using
<code><a href="https://rdrr.io/r/base/source.html" class="external-link">source()</a></code> or similar.</p>
<pre><code><span><span class="co">#| flags-dest: ./flags.R</span></span>
<span></span>
<span><span class="va">FLAGS</span> <span class="op">&lt;-</span> <span class="fu">envir</span><span class="fu">::</span><span class="fu"><a href="https://t-kalinowski.github.io/envir/reference/include.html" class="external-link">include</a></span><span class="op">(</span><span class="st">"flags.R"</span>, <span class="fu"><a href="https://rdrr.io/r/base/environment.html" class="external-link">new.env</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre>
<p>YAML files are also supported as a flags destination:</p>
<pre><code><span><span class="co">#| flags-dest: ./flags.yml</span></span>
<span></span>
<span><span class="va">FLAGS</span> <span class="op">&lt;-</span> <span class="fu">yaml</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/yaml/man/read_yaml.html" class="external-link">read_yaml</a></span><span class="op">(</span><span class="st">"flags.yml"</span><span class="op">)</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="retreiving-run-flags">Retreiving Run Flags<a class="anchor" aria-label="anchor" href="#retreiving-run-flags"></a>
</h3>
<p>The flags and flag values associated with each runs are returned by
<code><a href="../reference/ls_runs.html">ls_runs()</a></code> as a nested dataframe under
<code>flags</code>.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">runs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ls_runs.html">ls_runs</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">runs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">shortId</span>, <span class="va">flags</span><span class="op">)</span> <span class="co">#%&gt;% tidyr::unnest(flags, names_sep = "_")</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 7 × 2</span></span></span>
<span><span class="co">#&gt;   shortId  flags$.fast $batch_size $epochs $learning_rate $units</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span>             <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>          <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> 4ad73fb7 FALSE                32      30          0.003    256</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span> 157f9b69 FALSE                32      30          0.003    128</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span> 7a9d1ce8 FALSE                32      30          0.001    256</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span> 44719bd4 FALSE                32      30          0.001    128</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span> ac078248 FALSE                32      30          0.001    256</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">6</span> 1d6e49cc FALSE                32      30          0.003    128</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">7</span> f4375fbc FALSE                32      20          0.001     64</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="scalars">Scalars<a class="anchor" aria-label="anchor" href="#scalars"></a>
</h2>
<p>The counterpart to run <code>flags</code> are run
<code>scalars</code>. Where as <code>flags</code> are a type of run
input, scalars are run outputs identified by Guild as meaningful to
track.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">runs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">shortId</span>, <span class="va">scalars</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 7 × 2</span></span></span>
<span><span class="co">#&gt;   shortId  scalars          </span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;list&gt;</span>           </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> 4ad73fb7 <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span> 157f9b69 <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span> 7a9d1ce8 <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">4</span> 44719bd4 <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">5</span> ac078248 <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">6</span> 1d6e49cc <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">7</span> f4375fbc <span style="color: #949494;">&lt;tibble [2 × 14]&gt;</span></span></span>
<span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">runs</span><span class="op">$</span><span class="va">scalars</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rows: 2</span></span>
<span><span class="co">#&gt; Columns: 14</span></span>
<span><span class="co">#&gt; $ run        <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "4ad73fb75e594fab97369480d01455c1", "4ad73fb75e594fab973694…</span></span>
<span><span class="co">#&gt; $ prefix     <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> ".guild", ".guild"</span></span>
<span><span class="co">#&gt; $ tag        <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "test_accuracy", "test_loss"</span></span>
<span><span class="co">#&gt; $ first_val  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ first_step <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 0</span></span>
<span><span class="co">#&gt; $ last_val   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ last_step  <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 0</span></span>
<span><span class="co">#&gt; $ min_val    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ min_step   <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 0</span></span>
<span><span class="co">#&gt; $ max_val    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ max_step   <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 0</span></span>
<span><span class="co">#&gt; $ avg_val    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ total      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.8751000, 0.4721423</span></span>
<span><span class="co">#&gt; $ count      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 1, 1</span></span></code></pre></div>
<p>Here we see that guild has automatically identified
<code>test_accuracy</code> and <code>test_loss</code> as run scalar
outputs. By default, any lines printed to standard output during the run
with the patten <code>"key: numeric-value"</code> are recorded by guild
as <code>scalars</code>. If you are printing values for the same scalar
<code>key</code> multiple times during a run (e.g, <code>loss</code>
during a training loop), then be sure to also print a <code>step</code>
scalar in between, to enable guild to track history (and enable
visualization of the run metrics with tensorboard).</p>
<p>Alternatively, if your run process produces tfevent records directly
(e.g., <code>keras::callback_tensorboard("./logs")</code>), then those
automatically identified by guild a run scalars, and included in
<code><a href="../reference/ls_runs.html">ls_runs()</a></code> (and <code><a href="../reference/guild_view.html">guild_view()</a></code>, and tensorboard
and other run views).</p>
<p><code><a href="../reference/ls_runs.html">ls_runs()</a></code> by default only returns a summary of run
scalars, but the full scalar history can also be accessed from R
directly:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ls_runs.html">ls_runs</a></span><span class="op">(</span>scalars <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 14 × 5</span></span></span>
<span><span class="co">#&gt;    run                              path   tag           value  step</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                            <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>         <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 4ad73fb75e594fab97369480d01455c1 .guild test_loss     0.472     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 4ad73fb75e594fab97369480d01455c1 .guild test_accuracy 0.875     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 157f9b69b3f748ae87300775d7b0d87a .guild test_loss     0.466     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 157f9b69b3f748ae87300775d7b0d87a .guild test_accuracy 0.874     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 7a9d1ce8b5c849b7bfde5fba78308253 .guild test_loss     0.446     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 7a9d1ce8b5c849b7bfde5fba78308253 .guild test_accuracy 0.883     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 44719bd4ec224af1811a0660608b8caa .guild test_loss     0.466     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 44719bd4ec224af1811a0660608b8caa .guild test_accuracy 0.876     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> ac078248d35b4b5d99815be775c40c0f .guild test_loss     0.449     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> ac078248d35b4b5d99815be775c40c0f .guild test_accuracy 0.884     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">11</span> 1d6e49cc32774746bf801cbbed187a51 .guild test_loss     0.470     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">12</span> 1d6e49cc32774746bf801cbbed187a51 .guild test_accuracy 0.878     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">13</span> f4375fbcfa6b4158b9f8017d87affad7 .guild test_loss     0.369     0</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">14</span> f4375fbcfa6b4158b9f8017d87affad7 .guild test_accuracy 0.882     0</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="using-flags-and-scalars-together">Using Flags and Scalars Together<a class="anchor" aria-label="anchor" href="#using-flags-and-scalars-together"></a>
</h2>
<p>We can use guild to explore what impact <code>units</code> has on
<code>test_accuracy</code>.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">units</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">2</span> <span class="op">^</span> <span class="op">(</span><span class="fl">4</span><span class="op">:</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html" class="external-link">diff</a></span><span class="op">(</span><span class="va">.</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">units</span> </span>
<span><span class="co">#&gt;  [1]   16   32   48   64   96  128  192  256  384  512  768 1024 1536 2048</span></span>
<span><span class="fu"><a href="../reference/guild_run.html">guild_run</a></span><span class="op">(</span><span class="st">"fashion-mnist.R"</span>, </span>
<span>          flags <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">units</span><span class="op">)</span>,</span>
<span>          echo <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in writeLines(out) : can only write character objects</span></span></code></pre></div>
<p>We can see compare run flags and run scalars from R:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">runs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ls_runs.html">ls_runs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"1:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># last 8 runs</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">runs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">flags</span>, <span class="va">scalars</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">rowwise</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span><span class="fu">across</span><span class="op">(</span><span class="va">scalars</span>, <span class="kw">function</span><span class="op">(</span><span class="va">run_scalars_df</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">run_scalars_df</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>      <span class="fu">select</span><span class="op">(</span><span class="va">tag</span>, <span class="va">last_val</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>      <span class="fu">tidyr</span><span class="fu">::</span><span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_wider.html" class="external-link">pivot_wider</a></span><span class="op">(</span>names_from <span class="op">=</span> <span class="va">tag</span>,</span>
<span>                         values_from <span class="op">=</span> <span class="va">last_val</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">tidyr</span><span class="fu">::</span><span class="fu"><a href="https://tidyr.tidyverse.org/reference/nest.html" class="external-link">unnest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">flags</span>, <span class="va">scalars</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">units</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 14 × 7</span></span></span>
<span><span class="co">#&gt;    .fast batch_size epochs learning_rate units test_accuracy test_loss</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>         <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>         <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> FALSE         32     30         0.003    16         0.847     0.459</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> FALSE         32     30         0.003    32         0.860     0.455</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> FALSE         32     30         0.003    48         0.873     0.438</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> FALSE         32     30         0.003    64         0.878     0.443</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> FALSE         32     30         0.003    96         0.878     0.491</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> FALSE         32     30         0.003   128         0.877     0.450</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> FALSE         32     30         0.003   192         0.876     0.472</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> FALSE         32     30         0.003   256         0.882     0.473</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> FALSE         32     30         0.003   384         0.882     0.438</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> FALSE         32     30         0.003   512         0.880     0.476</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">11</span> FALSE         32     30         0.003   768         0.870     0.505</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">12</span> FALSE         32     30         0.003  <span style="text-decoration: underline;">1</span>024         0.874     0.464</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">13</span> FALSE         32     30         0.003  <span style="text-decoration: underline;">1</span>536         0.865     0.543</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">14</span> FALSE         32     30         0.003  <span style="text-decoration: underline;">2</span>048         0.878     0.505</span></span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">units</span>, y <span class="op">=</span> <span class="va">test_accuracy</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html" class="external-link">geom_smooth</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-25-1.png" width="700"></p>
<div class="section level3">
<h3 id="addin">Addin<a class="anchor" aria-label="anchor" href="#addin"></a>
</h3>
<p>The <strong>guildai</strong> package installs an RStudio IDE addin
which provides quick access to frequently used functions from the Addins
menu:</p>
<p>Note that you can use <strong>Tools</strong> -&gt; <strong>Modify
Keyboard Shortcuts</strong> within RStudio to assign a keyboard shortcut
to one or more of the addin commands.</p>
</div>
<div class="section level3">
<h3 id="background-training">Background Training<a class="anchor" aria-label="anchor" href="#background-training"></a>
</h3>
<p>Since training runs can become quite lengthy, it’s often useful to
run them in the background in order to keep the R console free for other
work. You can launch a guild run without blocking the R console by
specifying <code>guild_run(wait = FALSE)</code> in the call. You can
then view real-time outputs from your run(s) using
<code><a href="../reference/guild_view.html">guild_view()</a></code>.</p>
<p>Alternatively, you can launch training runs in the terminal pane:</p>
<pre><code>Rscript -e 'guildai::guild_run("train.R")'</code></pre>
<p>If you are not running within RStudio then you can of course use a
system terminal window for background training.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
